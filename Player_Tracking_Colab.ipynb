{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Player Tracking System Comparison\n",
        "\n",
        "This notebook compares 3 different player tracking systems:\n",
        "- Eagle\n",
        "- Darkmyter (using Ultralytics YOLO)\n",
        "- Ultralytics YOLO 11 + Botsort\n",
        "\n",
        "**Important**: Run cells in order from top to bottom!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da177695-4e88-450f-cfe8-8d6d84e4ed61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Directory structure created\u001b[0m\n",
            "Working directory: /content\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup directories and utilities\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "BASE_DIR = Path(\"/content\")\n",
        "REPOS_DIR = BASE_DIR / \"repositories\"\n",
        "VIDEOS_DIR = BASE_DIR / \"videos\"\n",
        "CLIPS_DIR = BASE_DIR / \"clips\"\n",
        "OUTPUT_DIR = BASE_DIR / \"output\"\n",
        "\n",
        "for d in [REPOS_DIR, VIDEOS_DIR, CLIPS_DIR, OUTPUT_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def print_status(msg, status=\"INFO\"):\n",
        "    \"Print colored status messages\"\n",
        "    colors = {\n",
        "        \"INFO\": \"\\033[94m\",\n",
        "        \"SUCCESS\": \"\\033[92m\",\n",
        "        \"WARNING\": \"\\033[93m\",\n",
        "        \"ERROR\": \"\\033[91m\",\n",
        "        \"RESET\": \"\\033[0m\"\n",
        "    }\n",
        "    print(f\"{colors.get(status, '')}[{status}] {msg}{colors['RESET']}\")\n",
        "\n",
        "print_status(\"Directory structure created\", \"SUCCESS\")\n",
        "print(f\"Working directory: {BASE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "clone",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cdc45d9-7622-4f53-c3f2-f133a184d3dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Cloning repositories...\u001b[0m\n",
            "\u001b[94m[INFO] eagle: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] eagle: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] darkmyter: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] darkmyter: Cloned successfully\u001b[0m\n",
            "\u001b[92m[SUCCESS] Repository cloning complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Clone all repositories\n",
        "\n",
        "import subprocess\n",
        "\n",
        "REPOSITORIES = {\n",
        "    \"eagle\": \"https://github.com/nreHieW/Eagle.git\",\n",
        "    \"darkmyter\": \"https://github.com/Darkmyter/Football-Players-Tracking.git\",\n",
        "}\n",
        "\n",
        "print_status(\"Cloning repositories...\", \"INFO\")\n",
        "\n",
        "for name, url in REPOSITORIES.items():\n",
        "    repo_path = REPOS_DIR / name\n",
        "\n",
        "    if repo_path.exists():\n",
        "        print_status(f\"{name}: Already exists, skipping\", \"WARNING\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        print_status(f\"{name}: Cloning...\", \"INFO\")\n",
        "        result = subprocess.run(\n",
        "            [\"git\", \"clone\", url, str(repo_path)],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=300\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print_status(f\"{name}: Cloned successfully\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"{name}: Clone failed - {result.stderr[:100]}\", \"ERROR\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{name}: Clone failed - {str(e)}\", \"ERROR\")\n",
        "\n",
        "print_status(\"Repository cloning complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb709d8-3d2b-4d74-bfbb-3a2e7d21bf3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Installing dependencies...\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m634.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.4/335.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m138.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[92m[SUCCESS] Dependencies installed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Install dependencies\n",
        "\n",
        "print_status(\"Installing dependencies...\", \"INFO\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio tracklab\n",
        "!pip install -q opencv-python numpy scipy pandas scikit-learn matplotlib\n",
        "!pip install -q ultralytics supervision\n",
        "!pip install -q gdown Pillow tqdm requests\n",
        "\n",
        "print_status(\"Dependencies installed\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolo11m.pt\")\n",
        "print(\"Loaded weights from:\", getattr(model, \"ckpt_path\", \"unknown path\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzy7qI3atgID",
        "outputId": "6f8b1552-bcaf-4b4b-fe7a-671710e94d09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt': 100% ━━━━━━━━━━━━ 38.8MB 165.3MB/s 0.2s\n",
            "Loaded weights from: yolo11m.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "download_videos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6085ee8d-f795-4a87-9019-2c0951c9b060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Downloading videos from shared folder...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4\n",
            "Processing file 1RvqkxASOD23jfigqSgSgGja5_NGZReO4 FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\n",
            "Processing file 1urwKF6wjitkREymiNi9O3jCLLIysTp6F FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf\n",
            "From (redirected): https://drive.google.com/uc?id=1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf&confirm=t&uuid=0da4b685-2db4-460b-b81c-76b3bef0fecc\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4\n",
            "100%|██████████| 1.68G/1.68G [00:23<00:00, 71.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RvqkxASOD23jfigqSgSgGja5_NGZReO4\n",
            "From (redirected): https://drive.google.com/uc?id=1RvqkxASOD23jfigqSgSgGja5_NGZReO4&confirm=t&uuid=b79704f1-5ff7-495f-8d1c-b9de983e131b\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\n",
            "100%|██████████| 1.92G/1.92G [00:26<00:00, 71.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1urwKF6wjitkREymiNi9O3jCLLIysTp6F\n",
            "From (redirected): https://drive.google.com/uc?id=1urwKF6wjitkREymiNi9O3jCLLIysTp6F&confirm=t&uuid=fec2ff92-51b9-4c4c-98ec-f2950c1655aa\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4\n",
            "100%|██████████| 1.32G/1.32G [00:20<00:00, 66.0MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DOWNLOADED 3 VIDEO(S)\n",
            "==================================================\n",
            "1. FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4 (1832.4 MB)\n",
            "2. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4 (1604.1 MB)\n",
            "3. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4 (1260.8 MB)\n",
            "\n",
            "\n",
            "VIDEO SELECTION\n",
            "\n",
            "How many videos do you want to evaluate?\n",
            "  - Enter a number between 1 and 3\n",
            "  - Enter 'all' or leave blank to process ALL 3 videos\n",
            "\n",
            "Number of videos: \n",
            "\u001b[92m[SUCCESS] Selected ALL 3 videos\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Download videos from Google Drive\n",
        "\n",
        "!pip install -q gdown\n",
        "\n",
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "# Shared folder ID\n",
        "FOLDER_ID = \"1Cs4kTX6GYwfcpKyDZdqRKBezz49wT7_N\"\n",
        "\n",
        "print_status(\"Downloading videos from shared folder...\", \"INFO\")\n",
        "\n",
        "try:\n",
        "    gdown.download_folder(\n",
        "        id=FOLDER_ID,\n",
        "        output=str(VIDEOS_DIR),\n",
        "        quiet=False,\n",
        "        use_cookies=False\n",
        "    )\n",
        "\n",
        "    # List downloaded videos\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.MP4', '.AVI', '.MOV', '.MKV']\n",
        "    available_videos = []\n",
        "\n",
        "    for ext in video_extensions:\n",
        "        available_videos.extend(list(VIDEOS_DIR.glob(f\"*{ext}\")))\n",
        "\n",
        "    if not available_videos:\n",
        "        print_status(\"No video files found\", \"ERROR\")\n",
        "    else:\n",
        "        print(f\"\\nDOWNLOADED {len(available_videos)} VIDEO(S)\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        for idx, video in enumerate(available_videos, 1):\n",
        "            size_mb = video.stat().st_size / (1024 * 1024)\n",
        "            print(f\"{idx}. {video.name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"VIDEO SELECTION\")\n",
        "\n",
        "        # Ask for number of videos\n",
        "        print(\"\\nHow many videos do you want to evaluate?\")\n",
        "        print(f\"  - Enter a number between 1 and {len(available_videos)}\")\n",
        "        print(f\"  - Enter 'all' or leave blank to process ALL {len(available_videos)} videos\")\n",
        "\n",
        "        num_selection = input(\"\\nNumber of videos: \").strip().lower()\n",
        "\n",
        "        VIDEO_PATHS = []\n",
        "\n",
        "        if not num_selection or num_selection == 'all':\n",
        "            VIDEO_PATHS = available_videos\n",
        "            print_status(f\"Selected ALL {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "        elif num_selection.isdigit():\n",
        "            num_videos = int(num_selection)\n",
        "            if 1 <= num_videos <= len(available_videos):\n",
        "                if num_videos == len(available_videos):\n",
        "                    VIDEO_PATHS = available_videos\n",
        "                else:\n",
        "                    print(f\"\\nSelect {num_videos} video(s) from the list above:\")\n",
        "                    print(\"  - Enter comma-separated numbers (e.g., '1,3,5')\")\n",
        "                    print(f\"  - Or enter 'first' to select the first {num_videos} videos\")\n",
        "\n",
        "                    video_selection = input(\"\\nYour selection: \").strip().lower()\n",
        "\n",
        "                    if video_selection == 'first':\n",
        "                        VIDEO_PATHS = available_videos[:num_videos]\n",
        "                    else:\n",
        "                        try:\n",
        "                            indices = [int(x.strip()) for x in video_selection.split(',')]\n",
        "                            if len(indices) != num_videos:\n",
        "                                print_status(f\"Warning: Selected {len(indices)} videos instead of {num_videos}\", \"WARNING\")\n",
        "                            for idx in indices[:num_videos]:\n",
        "                                if 1 <= idx <= len(available_videos):\n",
        "                                    VIDEO_PATHS.append(available_videos[idx - 1])\n",
        "                        except ValueError:\n",
        "                            print_status(\"Invalid input, selecting first videos\", \"WARNING\")\n",
        "                            VIDEO_PATHS = available_videos[:num_videos]\n",
        "\n",
        "                print_status(f\"Selected {len(VIDEO_PATHS)} video(s)\", \"SUCCESS\")\n",
        "                for video in VIDEO_PATHS:\n",
        "                    print(f\"  - {video.name}\")\n",
        "            else:\n",
        "                print_status(f\"Invalid number. Must be between 1 and {len(available_videos)}\", \"ERROR\")\n",
        "        else:\n",
        "            print_status(\"Invalid input\", \"ERROR\")\n",
        "\n",
        "        if not VIDEO_PATHS:\n",
        "            print_status(\"No videos selected\", \"ERROR\")\n",
        "\n",
        "except Exception as e:\n",
        "    print_status(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "    print(\"\\nNote: Make sure the folder is set to 'Anyone with the link can view'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "extract_clips",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401787f9-f998-4f20-f677-aa29f85e159b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PREPARING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "Duration: 6258.0s | FPS: 50.0 | Frames: 312900\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (15.5 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (15.4 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (21.8 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720\n",
            "Duration: 6152.3s | FPS: 25.0 | Frames: 153807\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (14.9 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (14.5 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (15.7 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p\n",
            "Duration: 5967.2s | FPS: 25.0 | Frames: 149181\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (9.3 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (10.4 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (11.4 MB)\u001b[0m\n",
            "\n",
            "\n",
            "PREPARATION COMPLETE\n",
            "Prepared 3 video(s) with both full and clip options\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Prepare videos and clips\n",
        "\n",
        "import cv2\n",
        "import subprocess\n",
        "\n",
        "CLIP_DURATION = 60\n",
        "\n",
        "# Prepare both full videos and clips\n",
        "FULL_VIDEOS = {}\n",
        "VIDEO_CLIPS = {}\n",
        "\n",
        "for VIDEO_PATH in VIDEO_PATHS:\n",
        "    VIDEO_NAME = VIDEO_PATH.stem\n",
        "\n",
        "    print(f\"\\nPREPARING: {VIDEO_NAME}\")\n",
        "\n",
        "    # Store full video path\n",
        "    FULL_VIDEOS[VIDEO_NAME] = {\"full\": VIDEO_PATH}\n",
        "\n",
        "    # Get video info for clip extraction\n",
        "    cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Duration: {duration:.1f}s | FPS: {fps:.1f} | Frames: {total_frames}\")\n",
        "\n",
        "    # Determine clip positions\n",
        "    if duration < CLIP_DURATION * 3:\n",
        "        if duration < CLIP_DURATION:\n",
        "            CLIPS = [(0, duration, \"full\")]\n",
        "            print_status(f\"Video shorter than {CLIP_DURATION}s, will use full video\", \"INFO\")\n",
        "        else:\n",
        "            CLIPS = [\n",
        "                (0, CLIP_DURATION, \"start\"),\n",
        "                (max(duration - CLIP_DURATION, 0), CLIP_DURATION, \"end\")\n",
        "            ]\n",
        "            print_status(\"Will extract start and end clips\", \"INFO\")\n",
        "    else:\n",
        "        CLIPS = [\n",
        "            (0, CLIP_DURATION, \"start\"),\n",
        "            ((duration - CLIP_DURATION) / 2, CLIP_DURATION, \"middle\"),\n",
        "            (duration - CLIP_DURATION, CLIP_DURATION, \"end\")\n",
        "        ]\n",
        "        print_status(\"Will extract start, middle, and end clips\", \"INFO\")\n",
        "\n",
        "    # Extract clips\n",
        "    CLIP_PATHS = {}\n",
        "    for start_time, clip_dur, position in CLIPS:\n",
        "        clip_name = f\"{VIDEO_NAME}_{position}.mp4\"\n",
        "        clip_path = CLIPS_DIR / clip_name\n",
        "\n",
        "        cmd = [\n",
        "            \"ffmpeg\", \"-i\", str(VIDEO_PATH),\n",
        "            \"-ss\", str(start_time),\n",
        "            \"-t\", str(clip_dur),\n",
        "            \"-c\", \"copy\",\n",
        "            str(clip_path),\n",
        "            \"-y\",\n",
        "            \"-loglevel\", \"error\"\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "        if result.returncode == 0 and clip_path.exists():\n",
        "            CLIP_PATHS[position] = clip_path\n",
        "            size_mb = clip_path.stat().st_size / (1024 * 1024)\n",
        "            print_status(f\"Clip '{position}' ready ({size_mb:.1f} MB)\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"Failed to extract '{position}' clip\", \"ERROR\")\n",
        "\n",
        "    VIDEO_CLIPS[VIDEO_NAME] = CLIP_PATHS\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"PREPARATION COMPLETE\")\n",
        "print(f\"Prepared {len(VIDEO_PATHS)} video(s) with both full and clip options\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell: Setup Eagle with Python 3.13\n",
        "\n",
        "print_status(\"Setting up Eagle with Python 3.13...\", \"INFO\")\n",
        "\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "# Install Python 3.13 (Eagle's required version)\n",
        "print_status(\"Installing Python 3.13...\", \"INFO\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y software-properties-common\n",
        "!add-apt-repository -y ppa:deadsnakes/ppa\n",
        "!apt-get update -qq\n",
        "!apt-get install -y python3.13 python3.13-venv python3.13-dev python3.13-distutils\n",
        "\n",
        "# Install pip for Python 3.13\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.13\n",
        "\n",
        "# Install uv if not already installed\n",
        "print_status(\"Installing uv...\", \"INFO\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "\n",
        "# Add uv to PATH\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/.local/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# Create Eagle environment with Python 3.13\n",
        "os.chdir(eagle_dir)\n",
        "print_status(\"Creating Eagle environment with Python 3.13...\", \"INFO\")\n",
        "!uv venv --python python3.13\n",
        "!uv sync\n",
        "\n",
        "# Download model weights\n",
        "print_status(\"Downloading Eagle model weights...\", \"INFO\")\n",
        "models_dir = eagle_dir / \"eagle\" / \"models\"\n",
        "if models_dir.exists():\n",
        "    os.chdir(models_dir)\n",
        "    !bash get_weights.sh\n",
        "    os.chdir(eagle_dir)\n",
        "    print_status(\"Eagle weights downloaded\", \"SUCCESS\")\n",
        "else:\n",
        "    print_status(\"Eagle models directory not found\", \"ERROR\")\n",
        "\n",
        "# Create Eagle wrapper that uses Python 3.13\n",
        "\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "eagle_wrapper.write_text('''\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Clean Eagle wrapper that produces a single output file\n",
        "Consolidates Eagle's multiple outputs into the format expected by the evaluation pipeline\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "\n",
        "def consolidate_eagle_output(eagle_output_dir, output_format=\"tracking\"):\n",
        "    \"\"\"\n",
        "    Consolidate Eagle's output into a single JSON file\n",
        "\n",
        "    Args:\n",
        "        eagle_output_dir: Path to Eagle's output directory\n",
        "        output_format: \"tracking\" for standard format, \"raw\" for Eagle's native format\n",
        "\n",
        "    Returns:\n",
        "        Consolidated data dictionary\n",
        "    \"\"\"\n",
        "    # Look for raw_coordinates folder\n",
        "    coords_dir = eagle_output_dir / \"raw_coordinates\"\n",
        "    if not coords_dir.exists():\n",
        "        coords_dir = eagle_output_dir\n",
        "\n",
        "    # Find the main coordinates file\n",
        "    raw_coords_file = coords_dir / \"raw_coordinates.json\"\n",
        "    raw_data_file = coords_dir / \"raw_data.json\"\n",
        "    processed_file = coords_dir / \"processed_data.json\"\n",
        "\n",
        "    # Try different file options in order of preference\n",
        "    data = None\n",
        "    source_file = None\n",
        "\n",
        "    for file_path in [raw_coords_file, processed_file, raw_data_file]:\n",
        "        if file_path.exists():\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            source_file = file_path\n",
        "            print(f\"[Eagle] Using {file_path.name} as source\", file=sys.stderr)\n",
        "            break\n",
        "\n",
        "    if data is None:\n",
        "        # Try to find any JSON file\n",
        "        json_files = list(coords_dir.glob(\"*.json\"))\n",
        "        if json_files:\n",
        "            with open(json_files[0], 'r') as f:\n",
        "                data = json.load(f)\n",
        "            source_file = json_files[0]\n",
        "            print(f\"[Eagle] Using {json_files[0].name} as source\", file=sys.stderr)\n",
        "\n",
        "    if data is None:\n",
        "        print(\"[Eagle] No output files found\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "    # Convert to standard tracking format if requested\n",
        "    if output_format == \"tracking\":\n",
        "        return convert_to_tracking_format(data, source_file)\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def convert_to_tracking_format(eagle_data, source_file):\n",
        "    \"\"\"\n",
        "    Convert Eagle's format to standard tracking format\n",
        "    [{\"frame_id\": N, \"track_id\": M, \"bbox\": [x1,y1,x2,y2], \"score\": S, \"class_id\": C}, ...]\n",
        "    \"\"\"\n",
        "    tracking_data = []\n",
        "\n",
        "    # Handle different Eagle output formats\n",
        "    if isinstance(eagle_data, dict) and all(key.isdigit() for key in eagle_data.keys()):\n",
        "        # Format: {\"0\": {...}, \"1\": {...}, ...} - raw_coordinates.json format\n",
        "        for frame_str, frame_data in eagle_data.items():\n",
        "            frame_id = int(frame_str)\n",
        "\n",
        "            if 'Coordinates' in frame_data:\n",
        "                coords = frame_data['Coordinates']\n",
        "\n",
        "                # Process players\n",
        "                for player_id, player_data in coords.get('Player', {}).items():\n",
        "                    if 'BBox' in player_data:\n",
        "                        tracking_data.append({\n",
        "                            'frame_id': frame_id,\n",
        "                            'track_id': int(player_id),\n",
        "                            'bbox': player_data['BBox'],\n",
        "                            'score': player_data.get('Confidence', 1.0),\n",
        "                            'class_id': 0  # Player\n",
        "                        })\n",
        "\n",
        "                # Process goalkeepers\n",
        "                for gk_id, gk_data in coords.get('Goalkeeper', {}).items():\n",
        "                    if 'BBox' in gk_data:\n",
        "                        tracking_data.append({\n",
        "                            'frame_id': frame_id,\n",
        "                            'track_id': int(gk_id),\n",
        "                            'bbox': gk_data['BBox'],\n",
        "                            'score': gk_data.get('Confidence', 1.0),\n",
        "                            'class_id': 1  # Goalkeeper\n",
        "                        })\n",
        "\n",
        "    elif isinstance(eagle_data, list):\n",
        "        # Format: [{...}, {...}, ...] - raw_data.json format\n",
        "        for frame_id, frame_data in enumerate(eagle_data):\n",
        "            # Process player entries\n",
        "            for key in frame_data:\n",
        "                if key.startswith('Player_') and '_video' in key:\n",
        "                    player_id = int(key.replace('Player_', '').replace('_video', ''))\n",
        "                    coords = frame_data.get(key)\n",
        "\n",
        "                    if coords is not None:\n",
        "                        # Convert center point to bounding box\n",
        "                        cx, cy = coords\n",
        "                        # Estimate bbox (can be adjusted based on typical player size)\n",
        "                        half_width, half_height = 10, 20\n",
        "\n",
        "                        tracking_data.append({\n",
        "                            'frame_id': frame_id,\n",
        "                            'track_id': player_id,\n",
        "                            'bbox': [cx - half_width, cy - half_height,\n",
        "                                   cx + half_width, cy + half_height],\n",
        "                            'score': 1.0,\n",
        "                            'class_id': 0  # Player\n",
        "                        })\n",
        "\n",
        "                elif key.startswith('Goalkeeper_') and '_video' in key:\n",
        "                    gk_id = int(key.replace('Goalkeeper_', '').replace('_video', ''))\n",
        "                    coords = frame_data.get(key)\n",
        "\n",
        "                    if coords is not None:\n",
        "                        cx, cy = coords\n",
        "                        half_width, half_height = 10, 20\n",
        "\n",
        "                        tracking_data.append({\n",
        "                            'frame_id': frame_id,\n",
        "                            'track_id': gk_id,\n",
        "                            'bbox': [cx - half_width, cy - half_height,\n",
        "                                   cx + half_width, cy + half_height],\n",
        "                            'score': 1.0,\n",
        "                            'class_id': 1  # Goalkeeper\n",
        "                        })\n",
        "\n",
        "    return tracking_data\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='Eagle wrapper for unified output')\n",
        "    parser.add_argument('--video', required=True, help='Path to input video')\n",
        "    parser.add_argument('--output', required=True, help='Path to output JSON file')\n",
        "    parser.add_argument('--fps', default=20, type=int, help='FPS to process (default: 20)')\n",
        "    parser.add_argument('--format', choices=['tracking', 'raw'], default='raw',\n",
        "                       help='Output format: tracking (standard) or raw (Eagle native)')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: Video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Set up environment\n",
        "    env = os.environ.copy()\n",
        "    env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "    # Run Eagle\n",
        "    cmd = [\n",
        "        \"uv\", \"run\", \"--python\", \"python3.13\",\n",
        "        \"main.py\",\n",
        "        \"--video_path\", str(video_path),\n",
        "        \"--fps\", str(args.fps),\n",
        "    ]\n",
        "\n",
        "    print(f\"[Eagle] Processing {video_path.name} at {args.fps} FPS...\", file=sys.stderr)\n",
        "    start = time.time()\n",
        "\n",
        "    eagle_dir = Path(__file__).parent\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        cwd=eagle_dir,\n",
        "        timeout=600,  # 10 minute timeout\n",
        "        env=env,\n",
        "    )\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"[Eagle] Processing took {elapsed:.1f}s\", file=sys.stderr)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\"[Eagle] Warning: Process returned {result.returncode}\", file=sys.stderr)\n",
        "        if result.stderr:\n",
        "            print(f\"[Eagle] Stderr: {result.stderr[:500]}\", file=sys.stderr)\n",
        "\n",
        "    # Find Eagle's output directory\n",
        "    video_stem = video_path.stem\n",
        "    eagle_output_base = eagle_dir / \"output\"\n",
        "    eagle_output_dir = eagle_output_base / video_stem\n",
        "\n",
        "    if not eagle_output_dir.exists():\n",
        "        # Try to find directory with video name in it\n",
        "        for d in eagle_output_base.iterdir():\n",
        "            if d.is_dir() and video_stem in d.name:\n",
        "                eagle_output_dir = d\n",
        "                break\n",
        "\n",
        "    if not eagle_output_dir.exists():\n",
        "        print(f\"[Eagle] Error: Could not find output directory for {video_stem}\", file=sys.stderr)\n",
        "        # Write empty output\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump([], f)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Convert Eagle output into single file\n",
        "    print(f\"[Eagle] Consolidating output from {eagle_output_dir}\", file=sys.stderr)\n",
        "    consolidated_data = consolidate_eagle_output(eagle_output_dir, args.format)\n",
        "\n",
        "    # Write converted output\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(consolidated_data, f, indent=2)\n",
        "\n",
        "    # Report statistics\n",
        "    if isinstance(consolidated_data, list):\n",
        "        if consolidated_data and 'frame_id' in consolidated_data[0]:\n",
        "            # Tracking format\n",
        "            frame_ids = set(d['frame_id'] for d in consolidated_data)\n",
        "            track_ids = set(d['track_id'] for d in consolidated_data)\n",
        "            print(f\"[Eagle] Output: {len(consolidated_data)} detections\", file=sys.stderr)\n",
        "            print(f\"[Eagle] Frames: {len(frame_ids)} ({min(frame_ids)}-{max(frame_ids)})\", file=sys.stderr)\n",
        "            print(f\"[Eagle] Tracks: {len(track_ids)} unique IDs\", file=sys.stderr)\n",
        "        else:\n",
        "            print(f\"[Eagle] Output: {len(consolidated_data)} frames\", file=sys.stderr)\n",
        "    elif isinstance(consolidated_data, dict):\n",
        "        print(f\"[Eagle] Output: {len(consolidated_data)} frames (raw format)\", file=sys.stderr)\n",
        "\n",
        "    print(f\"[Eagle] Saved to: {output_path}\", file=sys.stderr)\n",
        "    sys.exit(0)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "''')\n",
        "\n",
        "eagle_wrapper.chmod(0o755)\n",
        "print_status(\"Eagle FULL capability wrapper created\", \"SUCCESS\")"
      ],
      "metadata": {
        "id": "jIMyv7HMfsbb",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50d1ae8-b3b7-4cbc-9524-2e9e4680c08a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Eagle with Python 3.13...\u001b[0m\n",
            "\u001b[94m[INFO] Installing Python 3.13...\u001b[0m\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Repository: 'deb https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu/ jammy main'\n",
            "Description:\n",
            "This PPA contains more recent Python versions packaged for Ubuntu.\n",
            "\n",
            "Disclaimer: there's no guarantee of timely updates in case of security problems or other issues. If you want to use them in a security-or-otherwise-critical environment (say, on a production server), you do so at your own risk.\n",
            "\n",
            "Update Note\n",
            "===========\n",
            "Please use this repository instead of ppa:fkrull/deadsnakes.\n",
            "\n",
            "Reporting Issues\n",
            "================\n",
            "\n",
            "Issues can be reported in the master issue tracker at:\n",
            "https://github.com/deadsnakes/issues/issues\n",
            "\n",
            "Supported Ubuntu and Python Versions\n",
            "====================================\n",
            "\n",
            "- Ubuntu 22.04 (jammy) Python3.7 - Python3.9, Python3.11 - Python3.13\n",
            "- Ubuntu 24.04 (noble) Python3.7 - Python3.11, Python3.13\n",
            "- Note: Python 3.10 (jammy), Python3.12 (noble) are not provided by deadsnakes as upstream ubuntu provides those packages.\n",
            "\n",
            "Why some packages aren't built:\n",
            "- Note: for jammy and noble, older python versions requre libssl<3 so they are not currently built\n",
            "- If you need these, reach out to asottile to set up a private ppa\n",
            "\n",
            "The packages may also work on other versions of Ubuntu or Debian, but that is not tested or supported.\n",
            "\n",
            "Packages\n",
            "========\n",
            "\n",
            "The packages provided here are loosely based on the debian upstream packages with some modifications to make them more usable as non-default pythons and on ubuntu.  As such, the packages follow debian's patterns and often do not include a full python distribution with just `apt install python#.#`.  Here is a list of packages that may be useful along with the default install:\n",
            "\n",
            "- `python#.#-dev`: includes development headers for building C extensions\n",
            "- `python#.#-venv`: provides the standard library `venv` module\n",
            "- `python#.#-distutils`: provides the standard library `distutils` module\n",
            "- `python#.#-lib2to3`: provides the `2to3-#.#` utility as well as the standard library `lib2to3` module\n",
            "- `python#.#-gdbm`: provides the standard library `dbm.gnu` module\n",
            "- `python#.#-tk`: provides the standard library `tkinter` module\n",
            "\n",
            "Third-Party Python Modules\n",
            "==========================\n",
            "\n",
            "Python modules in the official Ubuntu repositories are packaged to work with the Python interpreters from the official repositories. Accordingly, they generally won't work with the Python interpreters from this PPA. As an exception, pure-Python modules for Python 3 will work, but any compiled extension modules won't.\n",
            "\n",
            "To install 3rd-party Python modules, you should use the common Python packaging tools.  For an introduction into the Python packaging ecosystem and its tools, refer to the Python Packaging User Guide:\n",
            "https://packaging.python.org/installing/\n",
            "\n",
            "Sources\n",
            "=======\n",
            "The package sources are available at:\n",
            "https://github.com/deadsnakes/\n",
            "\n",
            "Nightly Builds\n",
            "==============\n",
            "\n",
            "For nightly builds, see ppa:deadsnakes/nightly https://launchpad.net/~deadsnakes/+archive/ubuntu/nightly\n",
            "More info: https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa\n",
            "Adding repository.\n",
            "Found existing deb entry in /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding deb entry to /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Found existing deb-src entry in /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/deadsnakes-ubuntu-ppa.gpg with fingerprint F23C5A6CF475977595C89F51BA6932366A755776\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python3.13-distutils\n",
            "E: Couldn't find any package by glob 'python3.13-distutils'\n",
            "E: Couldn't find any package by regex 'python3.13-distutils'\n",
            "/bin/bash: line 1: python3.13: command not found\n",
            "curl: (23) Failure writing output to destination\n",
            "\u001b[94m[INFO] Installing uv...\u001b[0m\n",
            "downloading uv 0.9.11 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "\u001b[94m[INFO] Creating Eagle environment with Python 3.13...\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\n",
            "Using CPython \u001b[36m3.13.9\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
            "\u001b[2mResolved \u001b[1m119 packages\u001b[0m \u001b[2min 0.81ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m113 packages\u001b[0m \u001b[2min 1m 32s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m113 packages\u001b[0m \u001b[2min 739ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1malbucore\u001b[0m\u001b[2m==0.0.24\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1malbumentations\u001b[0m\u001b[2m==2.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbayesian-optimization\u001b[0m\u001b[2m==3.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.13.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mboxmot\u001b[0m\u001b[2m==15.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.19.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilterpy\u001b[0m\u001b[2m==1.4.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.59.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgdown\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.45\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.30.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlapx\u001b[0m\u001b[2m==0.5.11.post1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmplcursors\u001b[0m\u001b[2m==0.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmplsoccer\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python-headless\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpy-cpuinfo\u001b[0m\u001b[2m==9.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5\u001b[0m\u001b[2m==5.15.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5-qt5\u001b[0m\u001b[2m==5.15.17\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5-sip\u001b[0m\u001b[2m==12.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpysocks\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msimsimd\u001b[0m\u001b[2m==6.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstringzilla\u001b[0m\u001b[2m==3.12.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1multralytics\u001b[0m\u001b[2m==8.3.184\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1multralytics-thop\u001b[0m\u001b[2m==2.0.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1myacs\u001b[0m\u001b[2m==0.1.8\u001b[0m\n",
            "\u001b[94m[INFO] Downloading Eagle model weights...\u001b[0m\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI\n",
            "From (redirected): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI&confirm=t&uuid=cf0b5454-7593-4ace-ac4e-91ad686b913e\n",
            "To: /content/repositories/eagle/eagle/models/weights.zip\n",
            "100% 821M/821M [00:08<00:00, 93.1MB/s]\n",
            "Archive:  weights.zip\n",
            "  inflating: weights/detector_large_hd.pt  \n",
            "  inflating: weights/detector_medium.onnx  \n",
            "  inflating: weights/detector_large.onnx  \n",
            "  inflating: weights/detector_large.pt  \n",
            "  inflating: weights/detector_large_hd.onnx  \n",
            "  inflating: weights/detector_medium.pt  \n",
            "  inflating: weights/keypoints_main.pth  \n",
            "\u001b[92m[SUCCESS] Eagle weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Eagle FULL capability wrapper created\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell: Setup Darkmyter (ByteTrack + YOLO)\n",
        "\n",
        "print_status(\"Setting up Darkmyter tracking...\", \"INFO\")\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "darkmyter_dir = REPOS_DIR / \"darkmyter\"\n",
        "\n",
        "# Download football-specific weights\n",
        "weights_dir = darkmyter_dir / \"yolov8-weights\"\n",
        "weights_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "custom_weights = weights_dir / \"yolov8l-football-players.pt\"\n",
        "gdrive_id = \"12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\"\n",
        "\n",
        "def download_darkmyter_weights():\n",
        "    print_status(\"Downloading Darkmyter football weights...\", \"INFO\")\n",
        "    try:\n",
        "        try:\n",
        "            import gdown\n",
        "        except ImportError:\n",
        "            subprocess.run([\"pip\", \"install\", \"gdown\"], check=True)\n",
        "            import gdown\n",
        "\n",
        "        url = f\"https://drive.google.com/uc?id={gdrive_id}\"\n",
        "        gdown.download(url, str(custom_weights), quiet=False)\n",
        "        print_status(\"Darkmyter weights downloaded\", \"SUCCESS\")\n",
        "    except Exception as e:\n",
        "        print_status(f\"Failed to download weights: {e}\", \"ERROR\")\n",
        "\n",
        "# Check if weights exist and are valid\n",
        "if custom_weights.exists():\n",
        "    try:\n",
        "        with open(custom_weights, \"rb\") as f:\n",
        "            header = f.read(16)\n",
        "        if header.startswith(b\"<\"):\n",
        "            print_status(\"Weights file is HTML, re-downloading...\", \"ERROR\")\n",
        "            custom_weights.unlink(missing_ok=True)\n",
        "            download_darkmyter_weights()\n",
        "        else:\n",
        "            print_status(\"Darkmyter weights already present\", \"SUCCESS\")\n",
        "    except Exception:\n",
        "        custom_weights.unlink(missing_ok=True)\n",
        "        download_darkmyter_weights()\n",
        "else:\n",
        "    download_darkmyter_weights()\n",
        "\n",
        "# Create corrected Darkmyter wrapper\n",
        "darkmyter_wrapper = darkmyter_dir / \"run_darkmyter.py\"\n",
        "darkmyter_wrapper.write_text('''\n",
        "#!/usr/bin/env python\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    import torch\n",
        "except ImportError:\n",
        "    print(\"Error: ultralytics or torch not installed in this env\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    parser = argparse.ArgumentParser(description=\"Darkmyter: YOLOv8 + ByteTrack (football)\")\n",
        "    parser.add_argument(\"--video\", required=True, help=\"Path to input video\")\n",
        "    parser.add_argument(\"--output\", required=True, help=\"Path to output JSON (full format)\")\n",
        "    parser.add_argument(\"--conf\", type=float, default=0.3, help=\"Confidence threshold\")\n",
        "    parser.add_argument(\"--iou\", type=float, default=0.5, help=\"IoU threshold\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    repo_root = Path(__file__).resolve().parent\n",
        "    custom_weights = repo_root / \"yolov8-weights\" / \"yolov8l-football-players.pt\"\n",
        "\n",
        "    if custom_weights.exists():\n",
        "        print(f\"[Darkmyter] Using football-specific weights: {custom_weights}\", file=sys.stderr)\n",
        "        model = YOLO(str(custom_weights))\n",
        "        model_name = \"yolov8l-football\"\n",
        "        football_specific = True\n",
        "    else:\n",
        "        print(\"[Darkmyter] Football weights not found, falling back to yolov8x.pt\", file=sys.stderr)\n",
        "        model = YOLO(\"yolov8x.pt\")\n",
        "        model_name = \"yolov8x\"\n",
        "        football_specific = False\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"[Darkmyter] Device: {device}\", file=sys.stderr)\n",
        "\n",
        "    # Stream tracking results frame by frame\n",
        "    results_gen = model.track(\n",
        "        source=str(video_path),\n",
        "        tracker=\"bytetrack.yaml\",\n",
        "        conf=args.conf,\n",
        "        iou=args.iou,\n",
        "        stream=True,\n",
        "        device=device,\n",
        "        persist=True,\n",
        "        verbose=False,\n",
        "        save=False,\n",
        "    )\n",
        "\n",
        "    detections = []\n",
        "    total_tracks = set()\n",
        "    conf_values = []\n",
        "    frames_processed = 0\n",
        "\n",
        "    for frame_idx, r in enumerate(results_gen):\n",
        "        frames_processed = frame_idx + 1\n",
        "\n",
        "        boxes = getattr(r, \"boxes\", None)\n",
        "        if boxes is None or boxes.id is None:\n",
        "            continue\n",
        "\n",
        "        ids = boxes.id.cpu().tolist()\n",
        "        xyxy = boxes.xyxy.cpu().tolist()\n",
        "        scores = boxes.conf.cpu().tolist()\n",
        "        if boxes.cls is not None:\n",
        "            classes = boxes.cls.cpu().tolist()\n",
        "        else:\n",
        "            classes = [0] * len(ids)\n",
        "\n",
        "        for tid, box, score, cls in zip(ids, xyxy, scores, classes):\n",
        "            detections.append(\n",
        "                {\n",
        "                    \"frame_id\": int(frame_idx),\n",
        "                    \"track_id\": int(tid),\n",
        "                    \"bbox\": [float(box[0]), float(box[1]), float(box[2]), float(box[3])],\n",
        "                    \"score\": float(score),\n",
        "                    \"class_id\": int(cls),\n",
        "                }\n",
        "            )\n",
        "            total_tracks.add(int(tid))\n",
        "            conf_values.append(float(score))\n",
        "\n",
        "        if frame_idx % 100 == 0:\n",
        "            print(f\"[Darkmyter] Processed {frame_idx} frames...\", file=sys.stderr)\n",
        "\n",
        "    stats = {\n",
        "        \"total_tracks\": len(total_tracks),\n",
        "        \"frames_processed\": int(frames_processed),\n",
        "        \"avg_confidence\": (sum(conf_values) / len(conf_values)) if conf_values else 0.0,\n",
        "    }\n",
        "\n",
        "    # Create full output with all metadata\n",
        "    full_output = {\n",
        "        \"framework\": \"Darkmyter\",\n",
        "        \"model\": model_name,\n",
        "        \"tracker\": \"ByteTrack\",\n",
        "        \"features\": {\n",
        "            \"football_specific\": football_specific,\n",
        "            \"dual_threshold\": True,\n",
        "            \"optimized_for\": \"tactical_camera\",\n",
        "        },\n",
        "        \"detections\": detections,\n",
        "        \"statistics\": stats,\n",
        "    }\n",
        "\n",
        "    # Save output to the main output path\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with output_path.open(\"w\") as f:\n",
        "        json.dump(full_output, f, indent=2)\n",
        "\n",
        "    print(f\"[Darkmyter] Total detections: {len(detections)}\", file=sys.stderr)\n",
        "    print(f\"[Darkmyter] Unique tracks: {stats['total_tracks']}\", file=sys.stderr)\n",
        "    print(f\"[Darkmyter] Frames processed: {stats['frames_processed']}\", file=sys.stderr)\n",
        "    print(f\"[Darkmyter] Avg confidence: {stats['avg_confidence']:.3f}\", file=sys.stderr)\n",
        "    print(f\"[Darkmyter] Full output saved to: {output_path}\", file=sys.stderr)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "''')\n",
        "\n",
        "darkmyter_wrapper.chmod(0o755)\n",
        "print_status(\"Darkmyter wrapper created\", \"SUCCESS\")"
      ],
      "metadata": {
        "id": "H_etsZN8K1QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efdef6a4-ac0b-4f08-f202-ee3ebf3db95e",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Darkmyter tracking...\u001b[0m\n",
            "\u001b[94m[INFO] Downloading Darkmyter football weights...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\n",
            "From (redirected): https://drive.google.com/uc?id=12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx&confirm=t&uuid=7006243c-101e-4b7d-a536-047a2999bc0f\n",
            "To: /content/repositories/darkmyter/yolov8-weights/yolov8l-football-players.pt\n",
            "100%|██████████| 87.6M/87.6M [00:01<00:00, 59.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Darkmyter weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Darkmyter wrapper created\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import ultralytics\n",
        "\n",
        "REPOS_DIR = Path(\"/content/repositories\")\n",
        "ultra_dir = REPOS_DIR / \"ultra_trackers\"\n",
        "ultra_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# 1) Runner script: choose custom configs for bytetrack + botsort\n",
        "runner_script = ultra_dir / \"run_ultra_yolo_tracker.py\"\n",
        "runner_script.write_text(textwrap.dedent(\"\"\"\\\n",
        "    #!/usr/bin/env python\n",
        "    \\\"\\\"\\\"Run Ultralytics YOLO (v5 / v8 / v11 weights) with a chosen tracker and dump JSON tracks.\n",
        "\n",
        "    Usage:\n",
        "      python run_ultra_yolo_tracker.py \\\\\n",
        "          --video input.mp4 \\\\\n",
        "          --output output.json \\\\\n",
        "          --weights yolo11m.pt \\\\\n",
        "          --tracker botsort\n",
        "    \\\"\\\"\\\"\n",
        "\n",
        "    import argparse\n",
        "    import json\n",
        "    from pathlib import Path\n",
        "    from ultralytics import YOLO\n",
        "    import yaml\n",
        "\n",
        "    def main():\n",
        "        parser = argparse.ArgumentParser(description=\"YOLO + tracker to JSON\")\n",
        "        parser.add_argument(\"--video\", required=True, help=\"Path to input video\")\n",
        "        parser.add_argument(\"--output\", required=True, help=\"Path to output JSON\")\n",
        "        parser.add_argument(\n",
        "            \"--weights\",\n",
        "            default=\"yolo11m.pt\",\n",
        "            help=\"YOLO weights (e.g., yolov5s.pt, yolov8n.pt, yolo11m.pt, ...)\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--tracker\",\n",
        "            default=\"botsort\",\n",
        "            choices=[\"botsort\", \"bytetrack\", \"deepsort\"],\n",
        "            help=\"Which tracker to use\",\n",
        "        )\n",
        "        parser.add_argument(\"--conf\", type=float, default=0.3,\n",
        "                    help=\"Confidence threshold (detector)\")\n",
        "        parser.add_argument(\"--iou\", type=float, default=0.4,\n",
        "                    help=\"IOU threshold for NMS (lower = keep more boxes)\")\n",
        "        parser.add_argument(\"--imgsz\", type=int, default=1280,\n",
        "                    help=\"Image size for inference\")\n",
        "        parser.add_argument(\"--max-det\", type=int, default=300,\n",
        "                    help=\"Maximum detections per image\")\n",
        "\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        video_path = Path(args.video)\n",
        "        out_path = Path(args.output)\n",
        "\n",
        "        if not video_path.exists():\n",
        "            raise SystemExit(f\"Video not found: {video_path}\")\n",
        "\n",
        "        # Load YOLO model\n",
        "        model = YOLO(args.weights)\n",
        "\n",
        "        # Get the script's directory for saving custom configs\n",
        "        ultra_root = Path(__file__).resolve().parent\n",
        "\n",
        "        # Try to load Ultralytics default configs first\n",
        "        import ultralytics\n",
        "        ultra_path = Path(ultralytics.__file__).parent\n",
        "        tracker_base_path = ultra_path / \"cfg\" / \"trackers\"\n",
        "\n",
        "        # Select the default config path\n",
        "        if args.tracker == \"bytetrack\":\n",
        "            default_cfg_path = tracker_base_path / \"bytetrack.yaml\"\n",
        "        elif args.tracker == \"botsort\":\n",
        "            default_cfg_path = tracker_base_path / \"botsort.yaml\"\n",
        "        else:  # deepsort\n",
        "            default_cfg_path = tracker_base_path / \"deepsort.yaml\"\n",
        "\n",
        "        # Path for our custom config\n",
        "        custom_cfg_path = ultra_root / f\"{args.tracker}_football.yaml\"\n",
        "\n",
        "        # Load and modify the config\n",
        "        if default_cfg_path.exists():\n",
        "            # Load the default config\n",
        "            with open(default_cfg_path, 'r') as f:\n",
        "                tracker_cfg = yaml.safe_load(f)\n",
        "\n",
        "            # Modify with football-optimized values\n",
        "            if args.tracker == \"bytetrack\":\n",
        "                tracker_cfg.update({\n",
        "                    \"track_high_thresh\": 0.5,\n",
        "                    \"track_low_thresh\": 0.1,\n",
        "                    \"new_track_thresh\": 0.6,\n",
        "                    \"track_buffer\": 30,\n",
        "                    \"match_thresh\": 0.7,\n",
        "                    \"min_box_area\": 100,\n",
        "                    \"mot20\": False,\n",
        "                })\n",
        "            elif args.tracker == \"botsort\":\n",
        "                tracker_cfg.update({\n",
        "                    \"track_high_thresh\": 0.5,\n",
        "                    \"track_low_thresh\": 0.1,\n",
        "                    \"new_track_thresh\": 0.6,\n",
        "                    \"track_buffer\": 30,\n",
        "                    \"match_thresh\": 0.8,\n",
        "                    \"proximity_thresh\": 0.5,\n",
        "                    \"appearance_thresh\": 0.25,\n",
        "                    \"cmc_method\": \"sparseOptFlow\",\n",
        "                    \"frame_rate\": 30,\n",
        "                    \"lambda_\": 0.985,\n",
        "                    \"with_reid\":True\n",
        "                })\n",
        "            elif args.tracker == \"deepsort\":\n",
        "                tracker_cfg.update({\n",
        "                    \"track_high_thresh\": 0.5,\n",
        "                    \"track_low_thresh\": 0.1,\n",
        "                    \"track_buffer\": 30,\n",
        "                    \"match_thresh\": 0.7,\n",
        "                })\n",
        "\n",
        "            # Save the modified config to a file\n",
        "            with open(custom_cfg_path, 'w') as f:\n",
        "                yaml.dump(tracker_cfg, f)\n",
        "\n",
        "            # Use the custom config FILE PATH (not the dictionary!)\n",
        "            tracker_cfg_path = str(custom_cfg_path)\n",
        "        else:\n",
        "            # Fallback: just use the default tracker name\n",
        "            print(f\"Warning: Could not find default config at {default_cfg_path}\")\n",
        "            print(f\"Using default tracker: {args.tracker}.yaml\")\n",
        "            tracker_cfg_path = f\"{args.tracker}.yaml\"\n",
        "\n",
        "        # Run tracking with the config FILE PATH\n",
        "        results = model.track(\n",
        "            source=str(video_path),\n",
        "            tracker=tracker_cfg_path,  # Pass the FILE PATH, not dictionary!\n",
        "            conf=args.conf,\n",
        "            iou=args.iou,\n",
        "            imgsz=args.imgsz,\n",
        "            max_det=args.max_det,\n",
        "            stream=True,\n",
        "            device=0,\n",
        "            save=False,\n",
        "            verbose=False,\n",
        "            persist=True,\n",
        "            vid_stride=1,\n",
        "        )\n",
        "\n",
        "        print(f\"Tracking with {args.tracker} on device: {model.device}\")\n",
        "\n",
        "        all_detections = []\n",
        "        frame_idx = 0\n",
        "\n",
        "        for r in results:\n",
        "            boxes = r.boxes\n",
        "            if boxes is None:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            ids = boxes.id\n",
        "            if ids is None:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            xyxy = boxes.xyxy\n",
        "            confs = boxes.conf\n",
        "            clses = boxes.cls\n",
        "\n",
        "            ids = ids.cpu().tolist()\n",
        "            xyxy = xyxy.cpu().tolist()\n",
        "            confs = confs.cpu().tolist()\n",
        "            clses = clses.cpu().tolist()\n",
        "\n",
        "            for tid, (x1, y1, x2, y2), score, c in zip(ids, xyxy, confs, clses):\n",
        "                all_detections.append({\n",
        "                    \"frame_id\": frame_idx,\n",
        "                    \"track_id\": int(tid),\n",
        "                    \"bbox\": [float(x1), float(y1), float(x2), float(y2)],\n",
        "                    \"score\": float(score),\n",
        "                    \"class_id\": int(c),\n",
        "                })\n",
        "\n",
        "            frame_idx += 1\n",
        "\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with out_path.open(\"w\") as f:\n",
        "            json.dump(all_detections, f)\n",
        "\n",
        "        print(f\"Wrote {len(all_detections)} tracked detections to {out_path}\")\n",
        "\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        main()\n",
        "    \"\"\"))\n",
        "\n",
        "runner_script.chmod(0o755)\n",
        "print_status(\"Created wrapper for Botsort and Bytetrack\", \"SUCCESS\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I5iE6qiWWTy",
        "outputId": "6faced7c-7207-4892-ee84-01711c2470cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Created wrapper for Botsort and Bytetrack\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Final System Evaluation\n",
        "\n",
        "import time\n",
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# System configurations\n",
        "SYSTEM_CONFIGS = {\n",
        "    \"yolo11_botsort\": {\n",
        "        \"path\": REPOS_DIR / \"ultra_trackers\",\n",
        "        \"script\": \"run_ultra_yolo_tracker.py\",\n",
        "        \"args\": [\"--weights\", \"yolo11m.pt\", \"--tracker\", \"botsort\", \"--conf\", \"0.4\"],\n",
        "    },\n",
        "    \"darkmyter\": {\n",
        "        \"path\": REPOS_DIR / \"darkmyter\",\n",
        "        \"script\": \"run_darkmyter.py\",\n",
        "    },\n",
        "    \"eagle\": {\n",
        "        \"path\": REPOS_DIR / \"eagle\",\n",
        "        \"script\": \"run_eagle.py\",\n",
        "        \"python\": \"python3.13\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# Ask user for processing mode\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EVALUATION MODE SELECTION\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nHow do you want to evaluate the videos?\")\n",
        "print(\"  1. Use clips (faster - 60s segments)\")\n",
        "print(\"  2. Use full videos (comprehensive but slower)\")\n",
        "\n",
        "mode_choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
        "USE_CLIPS = mode_choice != '2'\n",
        "\n",
        "if USE_CLIPS:\n",
        "    print_status(\"Mode: CLIP-BASED EVALUATION\", \"INFO\")\n",
        "    ALL_VIDEOS = VIDEO_CLIPS\n",
        "    eval_type = \"clips\"\n",
        "else:\n",
        "    print_status(\"Mode: FULL VIDEO EVALUATION\", \"INFO\")\n",
        "    ALL_VIDEOS = FULL_VIDEOS\n",
        "    eval_type = \"full\"\n",
        "\n",
        "position_to_number = {\"start\": 1, \"middle\": 2, \"end\": 3, \"full\": 1}\n",
        "\n",
        "def run_system_on_video(system_name, system_config, video_name, segment_name, video_path):\n",
        "    \"\"\"Run a tracking system on a video or clip\"\"\"\n",
        "\n",
        "    if USE_CLIPS:\n",
        "        segment_number = position_to_number.get(segment_name, 1)\n",
        "        output_dir = OUTPUT_DIR / video_name / \"clips\" / str(segment_number) / system_name\n",
        "    else:\n",
        "        output_dir = OUTPUT_DIR / video_name / \"full\" / system_name\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if USE_CLIPS:\n",
        "        print_status(f\"Running {system_name} on {video_name}/clip_{segment_number}...\", \"INFO\")\n",
        "    else:\n",
        "        print_status(f\"Running {system_name} on {video_name} (full video)...\", \"INFO\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    output_file = output_dir / f\"{system_name}_output.json\"\n",
        "    system_path = system_config.get(\"path\", REPOS_DIR)\n",
        "\n",
        "    # Build command\n",
        "    if system_name == \"eagle\":\n",
        "        cmd = [\n",
        "            \"uv\", \"run\", \"--python\", system_config.get(\"python\", \"python3.13\"),\n",
        "            \"run_eagle.py\",\n",
        "            \"--video\", str(video_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ]\n",
        "    else:\n",
        "        cmd = [\n",
        "            \"python\", system_config[\"script\"],\n",
        "            \"--video\", str(video_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ]\n",
        "        for extra in system_config.get(\"args\", []):\n",
        "            cmd.append(str(extra))\n",
        "\n",
        "    try:\n",
        "        # Set longer timeout for full videos\n",
        "        timeout = 1800 if not USE_CLIPS else 600\n",
        "\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=timeout,\n",
        "            cwd=str(system_path),\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        if result.returncode == 0 and output_file.exists():\n",
        "            try:\n",
        "                with open(output_file) as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                if isinstance(data, list):\n",
        "                    num_detections = len(data)\n",
        "                elif isinstance(data, dict):\n",
        "                    num_detections = sum(\n",
        "                        len(dets) if isinstance(dets, list) else 0\n",
        "                        for dets in data.values()\n",
        "                    )\n",
        "                else:\n",
        "                    num_detections = 0\n",
        "\n",
        "                print_status(\n",
        "                    f\"{system_name}: SUCCESS - {num_detections} detections in {elapsed:.1f}s\",\n",
        "                    \"SUCCESS\"\n",
        "                )\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"time\": elapsed,\n",
        "                    \"output\": str(output_file),\n",
        "                    \"detections\": num_detections,\n",
        "                }\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print_status(f\"{system_name}: Invalid JSON\", \"ERROR\")\n",
        "                return {\"success\": False, \"time\": elapsed, \"error\": f\"Invalid JSON: {e}\"}\n",
        "        else:\n",
        "            error_msg = result.stderr[-500:] if result.stderr else \"Unknown error\"\n",
        "            print_status(f\"{system_name}: FAILED\", \"ERROR\")\n",
        "            print(f\"Error: {error_msg}\")\n",
        "            return {\"success\": False, \"time\": elapsed, \"error\": error_msg}\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print_status(f\"{system_name}: TIMEOUT\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": timeout, \"error\": \"Timeout\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{system_name}: EXCEPTION - {str(e)}\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": time.time() - start_time, \"error\": str(e)}\n",
        "\n",
        "# Main evaluation\n",
        "print(f\"STARTING {eval_type.upper()} EVALUATION\")\n",
        "print(\"\\n\")\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for video_name, segments in ALL_VIDEOS.items():\n",
        "    print(f\"\\nVIDEO: {video_name}\")\n",
        "\n",
        "    video_results = {}\n",
        "\n",
        "    for segment_name, video_path in segments.items():\n",
        "        if USE_CLIPS:\n",
        "            segment_number = position_to_number.get(segment_name, 1)\n",
        "            segment_key = f\"clip_{segment_number}\"\n",
        "            print(f\"\\nProcessing clip {segment_number} ({segment_name})...\")\n",
        "        else:\n",
        "            segment_key = \"full\"\n",
        "            print(f\"\\nProcessing full video...\")\n",
        "\n",
        "        video_results[segment_key] = {}\n",
        "\n",
        "        for system_name, system_config in SYSTEM_CONFIGS.items():\n",
        "            result = run_system_on_video(\n",
        "                system_name, system_config, video_name, segment_name, video_path\n",
        "            )\n",
        "            video_results[segment_key][system_name] = result\n",
        "\n",
        "        successful = sum(1 for r in video_results[segment_key].values() if r[\"success\"])\n",
        "        total = len(video_results[segment_key])\n",
        "\n",
        "        if USE_CLIPS:\n",
        "            print(f\"Clip summary: {successful}/{total} systems succeeded\")\n",
        "        else:\n",
        "            print(f\"Video summary: {successful}/{total} systems succeeded\")\n",
        "\n",
        "    all_results[video_name] = video_results\n",
        "\n",
        "    summary_file = OUTPUT_DIR / video_name / f\"summary_{eval_type}.json\"\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        json.dump(video_results, f, indent=2)\n",
        "\n",
        "overall_summary = OUTPUT_DIR / f\"overall_summary_{eval_type}.json\"\n",
        "with open(overall_summary, \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "# Final statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"{eval_type.upper()} EVALUATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "system_stats = {sys: {\"success\": 0, \"total\": 0} for sys in SYSTEM_CONFIGS.keys()}\n",
        "\n",
        "for video_results in all_results.values():\n",
        "    for segment_results in video_results.values():\n",
        "        for system_name, result in segment_results.items():\n",
        "            system_stats[system_name][\"total\"] += 1\n",
        "            if result[\"success\"]:\n",
        "                system_stats[system_name][\"success\"] += 1\n",
        "\n",
        "print(\"\\nSystem Success Rates:\")\n",
        "for system_name, stats in system_stats.items():\n",
        "    if stats[\"total\"] > 0:\n",
        "        success_rate = (stats[\"success\"] / stats[\"total\"]) * 100\n",
        "        print(f\"  {system_name}: {stats['success']}/{stats['total']} ({success_rate:.1f}%)\")\n",
        "\n",
        "print(f\"\\nResults: {OUTPUT_DIR}\")\n",
        "print(f\"Summary: {overall_summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMRXc5GpkG4d",
        "outputId": "7e474a62-2899-42bf-ded5-b58c249ef225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "EVALUATION MODE SELECTION\n",
            "==================================================\n",
            "\n",
            "How do you want to evaluate the videos?\n",
            "  1. Use clips (faster - 60s segments)\n",
            "  2. Use full videos (comprehensive but slower)\n",
            "\n",
            "Enter your choice (1 or 2): 1\n",
            "\u001b[94m[INFO] Mode: CLIP-BASED EVALUATION\u001b[0m\n",
            "STARTING CLIPS EVALUATION\n",
            "\n",
            "\n",
            "\n",
            "VIDEO: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "\n",
            "Processing clip 1 (start)...\n",
            "\u001b[94m[INFO] Running yolo11_botsort on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n",
            "\u001b[92m[SUCCESS] yolo11_botsort: SUCCESS - 31472 detections in 224.5s\u001b[0m\n",
            "\u001b[94m[INFO] Running darkmyter on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n",
            "\u001b[92m[SUCCESS] darkmyter: SUCCESS - 57442 detections in 92.6s\u001b[0m\n",
            "\u001b[94m[INFO] Running eagle on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n",
            "\u001b[92m[SUCCESS] eagle: SUCCESS - 0 detections in 275.4s\u001b[0m\n",
            "Clip summary: 3/3 systems succeeded\n",
            "\n",
            "Processing clip 2 (middle)...\n",
            "\u001b[94m[INFO] Running yolo11_botsort on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_2...\u001b[0m\n",
            "\u001b[92m[SUCCESS] yolo11_botsort: SUCCESS - 50551 detections in 229.8s\u001b[0m\n",
            "\u001b[94m[INFO] Running darkmyter on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_2...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Evaluation Cell for Football Player Tracking Systems\n",
        "\n",
        "\"\"\"\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print_status(\"Starting comprehensive tracking evaluation...\", \"INFO\")\n",
        "\n",
        "# DATA STRUCTURES\n",
        "\n",
        "@dataclass\n",
        "class Detection:\n",
        "    \"\"\"Universal detection representation\"\"\"\n",
        "    frame_id: int\n",
        "    track_id: int\n",
        "    bbox: List[float]  # [x1, y1, x2, y2]\n",
        "    confidence: float = 1.0\n",
        "    class_id: int = 0\n",
        "\n",
        "    # Eagle-specific\n",
        "    transformed_coords: Optional[Tuple[float, float]] = None\n",
        "    is_goalkeeper: bool = False\n",
        "\n",
        "    # Metadata\n",
        "    source_system: str = \"\"\n",
        "    raw_data: Dict = field(default_factory=dict)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SystemData:\n",
        "    \"\"\"Container for system tracking data\"\"\"\n",
        "    name: str\n",
        "    frames: Dict[int, List[Detection]]\n",
        "    metadata: Dict[str, Any]\n",
        "    source_file: str\n",
        "    clip_name: str = \"\"\n",
        "\n",
        "\n",
        "\n",
        "# DATA LOADERS\n",
        "\n",
        "\n",
        "class UniversalLoader:\n",
        "    \"\"\"Load tracking data from different systems\"\"\"\n",
        "    @staticmethod\n",
        "    def load_eagle(filepath: Path) -> SystemData:\n",
        "        \"\"\"Load Eagle data (handles both raw_coordinates and standard format)\"\"\"\n",
        "        with open(filepath, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        from collections import defaultdict\n",
        "        frames = defaultdict(list)\n",
        "        metadata = {\"system\": \"Eagle\", \"features\": []}\n",
        "\n",
        "\n",
        "        # CASE 1: Eagle raw_coordinates format\n",
        "        if isinstance(data, dict) and data:\n",
        "            all_keys = list(data.keys())\n",
        "            if all(k.isdigit() for k in all_keys):\n",
        "                metadata[\"features\"] = [\"field_coordinates\", \"goalkeeper_detection\", \"keypoints\"]\n",
        "                metadata[\"format\"] = \"raw_coordinates\"\n",
        "\n",
        "                # iterate all frames, not just one\n",
        "                for frame_str in sorted(all_keys, key=lambda s: int(s)):\n",
        "                    frame_data = data[frame_str]\n",
        "                    frame_id = int(frame_str)\n",
        "\n",
        "                    coords = frame_data.get(\"Coordinates\", {})\n",
        "\n",
        "                    # Players\n",
        "                    for player_id, player_data in coords.get(\"Player\", {}).items():\n",
        "                        if \"BBox\" not in player_data:\n",
        "                            continue\n",
        "\n",
        "                        tc = player_data.get(\"Transformed_Coordinates\")\n",
        "                        if isinstance(tc, (list, tuple)) and len(tc) >= 2:\n",
        "                            transformed_coords = (float(tc[0]), float(tc[1]))\n",
        "                        else:\n",
        "                            transformed_coords = None\n",
        "\n",
        "                        det = Detection(\n",
        "                            frame_id=frame_id,\n",
        "                            track_id=int(player_id),\n",
        "                            bbox=player_data[\"BBox\"],\n",
        "                            confidence=player_data.get(\"Confidence\", 1.0),\n",
        "                            class_id=0,\n",
        "                            transformed_coords=transformed_coords,\n",
        "                            is_goalkeeper=False,\n",
        "                            source_system=\"Eagle\",\n",
        "                            raw_data=player_data,\n",
        "                        )\n",
        "                        frames[frame_id].append(det)\n",
        "\n",
        "                    # Goalkeepers\n",
        "                    for gk_id, gk_data in coords.get(\"Goalkeeper\", {}).items():\n",
        "                        if \"BBox\" not in gk_data:\n",
        "                            continue\n",
        "\n",
        "                        tc = gk_data.get(\"Transformed_Coordinates\")\n",
        "                        if isinstance(tc, (list, tuple)) and len(tc) >= 2:\n",
        "                            transformed_coords = (float(tc[0]), float(tc[1]))\n",
        "                        else:\n",
        "                            transformed_coords = None\n",
        "\n",
        "                        det = Detection(\n",
        "                            frame_id=frame_id,\n",
        "                            track_id=int(gk_id),\n",
        "                            bbox=gk_data[\"BBox\"],\n",
        "                            confidence=gk_data.get(\"Confidence\", 1.0),\n",
        "                            class_id=1,\n",
        "                            transformed_coords=transformed_coords,\n",
        "                            is_goalkeeper=True,\n",
        "                            source_system=\"Eagle\",\n",
        "                            raw_data=gk_data,\n",
        "                        )\n",
        "                        frames[frame_id].append(det)\n",
        "\n",
        "                    # Keypoints metadata\n",
        "                    if \"Keypoints\" in frame_data:\n",
        "                        metadata.setdefault(\"keypoints\", []).append(\n",
        "                            {\"frame\": frame_id, \"points\": frame_data[\"Keypoints\"]}\n",
        "                        )\n",
        "\n",
        "\n",
        "        # CASE 2: already in standard tracking format--\n",
        "        elif isinstance(data, list):\n",
        "            metadata[\"format\"] = \"standard\"\n",
        "            for det_dict in data:\n",
        "                det = Detection(\n",
        "                    frame_id=det_dict[\"frame_id\"],\n",
        "                    track_id=det_dict[\"track_id\"],\n",
        "                    bbox=det_dict[\"bbox\"],\n",
        "                    confidence=det_dict.get(\"score\", 1.0),\n",
        "                    class_id=det_dict.get(\"class_id\", 0),\n",
        "                    source_system=\"Eagle\",\n",
        "                )\n",
        "                frames[det.frame_id].append(det)\n",
        "\n",
        "        return SystemData(\n",
        "            name=\"Eagle\",\n",
        "            frames=dict(frames),\n",
        "            metadata=metadata,\n",
        "            source_file=str(filepath),\n",
        "        )\n",
        "    @staticmethod\n",
        "    def load_darkmyter(filepath: Path) -> SystemData:\n",
        "        \"\"\"Load Darkmyter data (YOLOv8 with ByteTrack)\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        frames = defaultdict(list)\n",
        "        metadata = {\"system\": \"Darkmyter\"}\n",
        "\n",
        "        # Check if it's the full format with metadata\n",
        "        if isinstance(data, dict) and 'framework' in data:\n",
        "            metadata.update({\n",
        "                \"model\": data.get('model', 'yolov8'),\n",
        "                \"tracker\": data.get('tracker', 'ByteTrack'),\n",
        "                \"features\": data.get('features', {}),\n",
        "                \"statistics\": data.get('statistics', {})\n",
        "            })\n",
        "            detections = data.get('detections', [])\n",
        "        else:\n",
        "            # Simple list format\n",
        "            detections = data if isinstance(data, list) else []\n",
        "\n",
        "        for det_dict in detections:\n",
        "            det = Detection(\n",
        "                frame_id=det_dict['frame_id'],\n",
        "                track_id=det_dict['track_id'],\n",
        "                bbox=det_dict['bbox'],\n",
        "                confidence=det_dict['score'],\n",
        "                class_id=det_dict['class_id'],\n",
        "                source_system=\"Darkmyter\"\n",
        "            )\n",
        "            frames[det.frame_id].append(det)\n",
        "\n",
        "        return SystemData(\n",
        "            name=\"Darkmyter\",\n",
        "            frames=dict(frames),\n",
        "            metadata=metadata,\n",
        "            source_file=str(filepath)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def load_yolo11(filepath: Path, tracker_name: str = \"YOLO11\") -> SystemData:\n",
        "        \"\"\"Load YOLO11 data (with BotSort or ByteTrack)\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        frames = defaultdict(list)\n",
        "        metadata = {\n",
        "            \"system\": tracker_name,\n",
        "            \"model\": \"YOLOv11\",\n",
        "            \"tracker\": \"BotSort\" if \"botsort\" in tracker_name.lower() else \"ByteTrack\"\n",
        "        }\n",
        "\n",
        "        # Handle both list and dict formats\n",
        "        detections = data if isinstance(data, list) else data.get('detections', [])\n",
        "\n",
        "        for det_dict in detections:\n",
        "            det = Detection(\n",
        "                frame_id=det_dict['frame_id'],\n",
        "                track_id=det_dict['track_id'],\n",
        "                bbox=det_dict['bbox'],\n",
        "                confidence=det_dict['score'],\n",
        "                class_id=det_dict['class_id'],\n",
        "                source_system=tracker_name\n",
        "            )\n",
        "            frames[det.frame_id].append(det)\n",
        "\n",
        "        return SystemData(\n",
        "            name=tracker_name,\n",
        "            frames=dict(frames),\n",
        "            metadata=metadata,\n",
        "            source_file=str(filepath)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "# EVALUATION METRICS\n",
        "\n",
        "\n",
        "class TrackingEvaluator:\n",
        "    \"\"\"Evaluate tracking performance\"\"\"\n",
        "\n",
        "    def __init__(self, iou_threshold: float = 0.5):\n",
        "        self.iou_threshold = iou_threshold\n",
        "\n",
        "    def calculate_iou(self, bbox1: List[float], bbox2: List[float]) -> float:\n",
        "        \"\"\"Calculate Intersection over Union\"\"\"\n",
        "        x1_min, y1_min, x1_max, y1_max = bbox1\n",
        "        x2_min, y2_min, x2_max, y2_max = bbox2\n",
        "\n",
        "        x_inter_min = max(x1_min, x2_min)\n",
        "        y_inter_min = max(y1_min, y2_min)\n",
        "        x_inter_max = min(x1_max, x2_max)\n",
        "        y_inter_max = min(y1_max, y2_max)\n",
        "\n",
        "        if x_inter_max < x_inter_min or y_inter_max < y_inter_min:\n",
        "            return 0.0\n",
        "\n",
        "        inter_area = (x_inter_max - x_inter_min) * (y_inter_max - y_inter_min)\n",
        "        area1 = (x1_max - x1_min) * (y1_max - y1_min)\n",
        "        area2 = (x2_max - x2_min) * (y2_max - y2_min)\n",
        "        union_area = area1 + area2 - inter_area\n",
        "\n",
        "        return inter_area / union_area if union_area > 0 else 0.0\n",
        "\n",
        "    def evaluate_system(self, system_data: SystemData) -> Dict:\n",
        "        \"\"\"Evaluate a single system\"\"\"\n",
        "        total_detections = sum(len(dets) for dets in system_data.frames.values())\n",
        "        unique_tracks = set()\n",
        "        confidence_values = []\n",
        "\n",
        "        for detections in system_data.frames.values():\n",
        "            for det in detections:\n",
        "                unique_tracks.add(det.track_id)\n",
        "                confidence_values.append(det.confidence)\n",
        "\n",
        "        # Track continuity analysis\n",
        "        track_lifetimes = defaultdict(list)\n",
        "        for frame_id, detections in system_data.frames.items():\n",
        "            for det in detections:\n",
        "                track_lifetimes[det.track_id].append(frame_id)\n",
        "\n",
        "        # Calculate fragmentations\n",
        "        fragmentations = 0\n",
        "        for track_id, frame_list in track_lifetimes.items():\n",
        "            frame_list = sorted(frame_list)\n",
        "            for i in range(1, len(frame_list)):\n",
        "                if frame_list[i] - frame_list[i-1] > 1:\n",
        "                    fragmentations += 1\n",
        "\n",
        "        # Eagle-specific metrics\n",
        "        eagle_metrics = {}\n",
        "        if system_data.name == \"Eagle\" and system_data.metadata.get('format') == 'raw_coordinates':\n",
        "            goalkeeper_count = sum(1 for dets in system_data.frames.values()\n",
        "                                 for det in dets if det.is_goalkeeper)\n",
        "            with_coords = sum(1 for dets in system_data.frames.values()\n",
        "                             for det in dets if det.transformed_coords)\n",
        "            eagle_metrics = {\n",
        "                'goalkeeper_detections': goalkeeper_count,\n",
        "                'detections_with_field_coords': with_coords,\n",
        "                'has_keypoints': 'keypoints' in system_data.metadata\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'system': system_data.name,\n",
        "            'clip': system_data.clip_name,\n",
        "            'total_frames': len(system_data.frames),\n",
        "            'total_detections': total_detections,\n",
        "            'unique_tracks': len(unique_tracks),\n",
        "            'avg_detections_per_frame': total_detections / len(system_data.frames) if system_data.frames else 0,\n",
        "            'avg_confidence': np.mean(confidence_values) if confidence_values else 0,\n",
        "            'std_confidence': np.std(confidence_values) if confidence_values else 0,\n",
        "            'fragmentations': fragmentations,\n",
        "            'avg_track_lifetime': np.mean([len(frames) for frames in track_lifetimes.values()]) if track_lifetimes else 0,\n",
        "            **eagle_metrics\n",
        "        }\n",
        "\n",
        "    def compare_systems(self, sys1: SystemData, sys2: SystemData) -> Dict:\n",
        "        \"\"\"Compare two systems on overlapping frames\"\"\"\n",
        "        common_frames = set(sys1.frames.keys()) & set(sys2.frames.keys())\n",
        "\n",
        "        if not common_frames:\n",
        "            return {\n",
        "                'comparison': f\"{sys1.name} vs {sys2.name}\",\n",
        "                'clip': sys1.clip_name,\n",
        "                'common_frames': 0,\n",
        "                'message': 'No overlapping frames'\n",
        "            }\n",
        "\n",
        "        matches = 0\n",
        "        total_iou = 0\n",
        "        sys1_only = 0\n",
        "        sys2_only = 0\n",
        "\n",
        "        for frame_id in common_frames:\n",
        "            dets1 = sys1.frames[frame_id]\n",
        "            dets2 = sys2.frames[frame_id]\n",
        "\n",
        "            matched2 = set()\n",
        "\n",
        "            for d1 in dets1:\n",
        "                best_iou = 0\n",
        "                best_match = None\n",
        "\n",
        "                for i, d2 in enumerate(dets2):\n",
        "                    if i in matched2:\n",
        "                        continue\n",
        "                    iou = self.calculate_iou(d1.bbox, d2.bbox)\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_match = i\n",
        "\n",
        "                if best_iou >= self.iou_threshold:\n",
        "                    matches += 1\n",
        "                    total_iou += best_iou\n",
        "                    matched2.add(best_match)\n",
        "                else:\n",
        "                    sys1_only += 1\n",
        "\n",
        "            sys2_only += len(dets2) - len(matched2)\n",
        "\n",
        "        return {\n",
        "            'comparison': f\"{sys1.name} vs {sys2.name}\",\n",
        "            'clip': sys1.clip_name,\n",
        "            'common_frames': len(common_frames),\n",
        "            'matched_detections': matches,\n",
        "            'avg_iou': total_iou / matches if matches > 0 else 0,\n",
        "            f'{sys1.name}_only': sys1_only,\n",
        "            f'{sys2.name}_only': sys2_only,\n",
        "            'match_rate': matches / (matches + sys1_only + sys2_only) if (matches + sys1_only + sys2_only) > 0 else 0\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# LOAD DATA FROM YOUR EXACT STRUCTURE\n",
        "\n",
        "\n",
        "def load_tracking_outputs_from_structure(base_dir: Path):\n",
        "    \"\"\"\n",
        "    Load tracking outputs from your directory structure:\n",
        "\n",
        "    /content/output/\n",
        "        <MATCH_NAME>/\n",
        "            clips/\n",
        "                1/\n",
        "                    darkmyter/darkmyter_output.json\n",
        "                    eagle/eagle_output.json\n",
        "                    yolo11_botsort/yolo11_botsort_output.json\n",
        "                    yolo11_bytetrack/yolo11_bytetrack_output.json\n",
        "    \"\"\"\n",
        "    systems = []\n",
        "    loader = UniversalLoader()\n",
        "\n",
        "    if not base_dir.exists():\n",
        "        print_status(f\"Base directory does not exist: {base_dir}\", \"ERROR\")\n",
        "        return systems\n",
        "\n",
        "    print_status(f\"Scanning directory: {base_dir}\", \"INFO\")\n",
        "\n",
        "    # Treat *every* subdirectory of base_dir as a match directory\n",
        "    for match_dir in sorted(base_dir.iterdir()):\n",
        "        if not match_dir.is_dir():\n",
        "            continue\n",
        "\n",
        "        match_name = match_dir.name\n",
        "        print_status(f\"Found match: {match_name}\", \"INFO\")\n",
        "\n",
        "        clips_dir = match_dir / \"clips\"\n",
        "        if not clips_dir.exists():\n",
        "            print_status(f\"  No clips directory in {match_name}\", \"WARNING\")\n",
        "            continue\n",
        "\n",
        "        # Process each clip folder (e.g., \"1\", \"2\", ...)\n",
        "        for clip_dir in sorted(clips_dir.iterdir()):\n",
        "            if not clip_dir.is_dir():\n",
        "                continue\n",
        "\n",
        "            clip_name = clip_dir.name\n",
        "            print_status(f\"  Processing clip {clip_name}...\", \"INFO\")\n",
        "\n",
        "            # Eagle\n",
        "            eagle_dir = clip_dir / \"eagle\"\n",
        "            if eagle_dir.exists():\n",
        "                eagle_file = eagle_dir / \"eagle_output.json\"\n",
        "                if eagle_file.exists():\n",
        "                    try:\n",
        "                        system_data = loader.load_eagle(eagle_file)\n",
        "                        system_data.clip_name = f\"{match_name}_clip_{clip_name}\"\n",
        "                        systems.append(system_data)\n",
        "                        print_status(\n",
        "                            f\"    ✓ Eagle: {len(system_data.frames)} frames\",\n",
        "                            \"SUCCESS\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        print_status(f\"    ✗ Eagle failed: {e}\", \"ERROR\")\n",
        "\n",
        "            #  Darkmyter\n",
        "            darkmyter_dir = clip_dir / \"darkmyter\"\n",
        "            if darkmyter_dir.exists():\n",
        "                darkmyter_file = darkmyter_dir / \"darkmyter_output.json\"\n",
        "                if darkmyter_file.exists():\n",
        "                    try:\n",
        "                        system_data = loader.load_darkmyter(darkmyter_file)\n",
        "                        system_data.clip_name = f\"{match_name}_clip_{clip_name}\"\n",
        "                        systems.append(system_data)\n",
        "                        print_status(\n",
        "                            f\"    ✓ Darkmyter: {len(system_data.frames)} frames\",\n",
        "                            \"SUCCESS\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        print_status(f\"    ✗ Darkmyter failed: {e}\", \"ERROR\")\n",
        "\n",
        "            #  YOLO11 BotSort\n",
        "            yolo11_botsort_dir = clip_dir / \"yolo11_botsort\"\n",
        "            if yolo11_botsort_dir.exists():\n",
        "                yolo11_botsort_file = yolo11_botsort_dir / \"yolo11_botsort_output.json\"\n",
        "                if yolo11_botsort_file.exists():\n",
        "                    try:\n",
        "                        system_data = loader.load_yolo11(\n",
        "                            yolo11_botsort_file,\n",
        "                            \"YOLO11-BotSort\"\n",
        "                        )\n",
        "                        system_data.clip_name = f\"{match_name}_clip_{clip_name}\"\n",
        "                        systems.append(system_data)\n",
        "                        print_status(\n",
        "                            f\"    ✓ YOLO11-BotSort: {len(system_data.frames)} frames\",\n",
        "                            \"SUCCESS\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        print_status(f\"    ✗ YOLO11-BotSort failed: {e}\", \"ERROR\")\n",
        "\n",
        "            #  YOLO11 ByteTrack\n",
        "            yolo11_bytetrack_dir = clip_dir / \"yolo11_bytetrack\"\n",
        "            if yolo11_bytetrack_dir.exists():\n",
        "                yolo11_bytetrack_file = (\n",
        "                    yolo11_bytetrack_dir / \"yolo11_bytetrack_output.json\"\n",
        "                )\n",
        "                if yolo11_bytetrack_file.exists():\n",
        "                    try:\n",
        "                        system_data = loader.load_yolo11(\n",
        "                            yolo11_bytetrack_file,\n",
        "                            \"YOLO11-ByteTrack\"\n",
        "                        )\n",
        "                        system_data.clip_name = f\"{match_name}_clip_{clip_name}\"\n",
        "                        systems.append(system_data)\n",
        "                        print_status(\n",
        "                            f\"    ✓ YOLO11-ByteTrack: {len(system_data.frames)} frames\",\n",
        "                            \"SUCCESS\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        print_status(f\"    ✗ YOLO11-ByteTrack failed: {e}\", \"ERROR\")\n",
        "\n",
        "    return systems\n",
        "\n",
        "\n",
        "    # Summary Statistics Table\n",
        "    ax6 = plt.subplot(2, 4, 6)\n",
        "    ax6.axis('tight')\n",
        "    ax6.axis('off')\n",
        "\n",
        "    if not eval_df.empty:\n",
        "        summary_data = []\n",
        "        for _, row in system_summary.iterrows():\n",
        "            summary_data.append([\n",
        "                row['system'],\n",
        "                f\"{int(row['total_frames'])}\",\n",
        "                f\"{int(row['total_detections'])}\",\n",
        "                f\"{row['unique_tracks']:.0f}\",\n",
        "                f\"{row['avg_confidence']:.3f}\"\n",
        "            ])\n",
        "\n",
        "        table = ax6.table(cellText=summary_data,\n",
        "                         colLabels=['System', 'Frames', 'Detections', 'Avg Tracks', 'Avg Conf'],\n",
        "                         cellLoc='center',\n",
        "                         loc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.5)\n",
        "\n",
        "    ax6.set_title('Aggregated Summary Statistics', pad=20)\n",
        "\n",
        "    plt.suptitle('Football Tracking Systems Evaluation', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "# MAIN EVALUATION EXECUTION\n",
        "\n",
        "\n",
        "# Set your base output directory\n",
        "OUTPUT_DIR = Path(\"/content/output\")  # Adjust this to your path\n",
        "\n",
        "# Load tracking data from your structure\n",
        "print_status(\"Loading tracking outputs...\", \"INFO\")\n",
        "systems = load_tracking_outputs_from_structure(OUTPUT_DIR)\n",
        "\n",
        "if not systems:\n",
        "    print_status(\"No tracking data found! Please check your output directory.\", \"ERROR\")\n",
        "    print_status(f\"Expected structure: {OUTPUT_DIR}/FULL_MATCH_*/clips/*/system_name/\", \"INFO\")\n",
        "else:\n",
        "    print_status(f\"Successfully loaded {len(systems)} system outputs\", \"SUCCESS\")\n",
        "\n",
        "    # Evaluate each system\n",
        "    evaluator = TrackingEvaluator(iou_threshold=0.5)\n",
        "    evaluation_results = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INDIVIDUAL SYSTEM EVALUATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for system in systems:\n",
        "        metrics = evaluator.evaluate_system(system)\n",
        "        evaluation_results.append(metrics)\n",
        "\n",
        "        print(f\"\\n{system.name} - {system.clip_name}:\")\n",
        "        print(f\"  Frames: {metrics['total_frames']}\")\n",
        "        print(f\"  Detections: {metrics['total_detections']}\")\n",
        "        print(f\"  Unique tracks: {metrics['unique_tracks']}\")\n",
        "        print(f\"  Avg confidence: {metrics['avg_confidence']:.3f}\")\n",
        "\n",
        "    # Pairwise comparisons within each clip\n",
        "    comparison_results = []\n",
        "\n",
        "    # Group systems by clip\n",
        "    clips = defaultdict(list)\n",
        "    for system in systems:\n",
        "        clips[system.clip_name].append(system)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PAIRWISE SYSTEM COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for clip_name, clip_systems in clips.items():\n",
        "        if len(clip_systems) > 1:\n",
        "            print(f\"\\nClip: {clip_name}\")\n",
        "\n",
        "            for i in range(len(clip_systems)):\n",
        "                for j in range(i+1, len(clip_systems)):\n",
        "                    comparison = evaluator.compare_systems(clip_systems[i], clip_systems[j])\n",
        "                    comparison_results.append(comparison)\n",
        "\n",
        "                    if comparison['common_frames'] > 0:\n",
        "                        print(f\"  {comparison['comparison']}:\")\n",
        "                        print(f\"    Common frames: {comparison['common_frames']}\")\n",
        "                        print(f\"    Match rate: {comparison['match_rate']:.3f}\")\n",
        "\n",
        "    # Create visualizations\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GENERATING EVALUATION PLOTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    fig = create_evaluation_plots(evaluation_results, comparison_results)\n",
        "\n",
        "    # Save results\n",
        "    eval_df = pd.DataFrame(evaluation_results)\n",
        "    eval_df.to_csv('tracking_evaluation_results.csv', index=False)\n",
        "    print_status(\"Results saved to tracking_evaluation_results.csv\", \"SUCCESS\")\n",
        "\n",
        "    if comparison_results:\n",
        "        comp_df = pd.DataFrame(comparison_results)\n",
        "        comp_df.to_csv('tracking_comparison_results.csv', index=False)\n",
        "        print_status(\"Comparisons saved to tracking_comparison_results.csv\", \"SUCCESS\")\n",
        "\n",
        "    # Display summary\n",
        "    print(\"\\n\")\n",
        "    print(\"EVALUATION SUMMARY\")\n",
        "\n",
        "    # Aggregate by system\n",
        "    system_avg = eval_df.groupby('system').agg({\n",
        "        'avg_confidence': 'mean',\n",
        "        'unique_tracks': 'mean',\n",
        "        'fragmentations': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    if not system_avg.empty:\n",
        "        best_confidence = system_avg.loc[system_avg['avg_confidence'].idxmax()]\n",
        "        best_tracks = system_avg.loc[system_avg['unique_tracks'].idxmax()]\n",
        "        best_continuity = system_avg.loc[system_avg['fragmentations'].idxmin()]\n",
        "\n",
        "        print(f\"\\nBest confidence: {best_confidence['system']} ({best_confidence['avg_confidence']:.3f})\")\n",
        "        print(f\"Most tracks: {best_tracks['system']} ({best_tracks['unique_tracks']:.0f} avg tracks)\")\n",
        "        print(f\"Best continuity: {best_continuity['system']} ({best_continuity['fragmentations']:.0f} total fragmentations)\")\n",
        "\n",
        "print_status(\"Evaluation complete!\", \"SUCCESS\")"
      ],
      "metadata": {
        "id": "CEQ4BiwHwTq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== DEBUG EAGLE OUTPUT FOR ONE CLIP ===================== #\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# --- Configure which match + clip to inspect ---\n",
        "MATCH_NAME = \"FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720\"\n",
        "CLIP_ID = \"2\"   # e.g. \"1\", \"2\", \"3\", ...\n",
        "\n",
        "BASE_OUTPUT_DIR = Path(\"/content/output\")\n",
        "eagle_json = BASE_OUTPUT_DIR / MATCH_NAME / \"clips\" / CLIP_ID / \"eagle\" / \"eagle_output.json\"\n",
        "\n",
        "print(\"=== PATH CHECK ===\")\n",
        "print(\"Eagle JSON path:\", eagle_json)\n",
        "print(\"Exists:\", eagle_json.exists())\n",
        "if not eagle_json.exists():\n",
        "    raise FileNotFoundError(eagle_json)\n",
        "\n",
        "# --- Inspect raw JSON structure ------------------------------------------- #\n",
        "with eagle_json.open(\"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(\"\\n=== RAW JSON STRUCTURE ===\")\n",
        "print(\"Top-level type:\", type(data))\n",
        "\n",
        "if isinstance(data, dict):\n",
        "    # Expect raw_coordinates.json style: {\"0\": {...}, \"1\": {...}, ...}\n",
        "    keys = list(data.keys())\n",
        "    print(\"Number of top-level keys (frames):\", len(keys))\n",
        "    print(\"First 10 keys:\", keys[:10])\n",
        "\n",
        "    frame_ids = []\n",
        "    det_per_frame = []\n",
        "    for frame_str, frame_data in data.items():\n",
        "        frame_id = int(frame_str)\n",
        "        frame_ids.append(frame_id)\n",
        "\n",
        "        coords = frame_data.get(\"Coordinates\", {})\n",
        "        n_players = len(coords.get(\"Player\", {}))\n",
        "        n_gks = len(coords.get(\"Goalkeeper\", {}))\n",
        "        det_per_frame.append(n_players + n_gks)\n",
        "\n",
        "    print(\"Frame id range:\", min(frame_ids), \"to\", max(frame_ids))\n",
        "    print(\"Detections per frame: min =\", min(det_per_frame),\n",
        "          \"max =\", max(det_per_frame),\n",
        "          \"mean =\", sum(det_per_frame) / len(det_per_frame))\n",
        "\n",
        "elif isinstance(data, list):\n",
        "    print(\"List length:\", len(data))\n",
        "    if data and isinstance(data[0], dict) and \"frame_id\" in data[0]:\n",
        "        # Our tracking format: [{\"frame_id\": ..., \"track_id\": ..., ...}, ...]\n",
        "        frame_ids = [d[\"frame_id\"] for d in data]\n",
        "        counts = Counter(frame_ids)\n",
        "        print(\"Number of distinct frame_ids:\", len(counts))\n",
        "        print(\"First 10 (frame_id: count):\", list(counts.items())[:10])\n",
        "\n",
        "print(\"\\n=== LOADER VIEW (UniversalLoader.load_eagle) ===\")\n",
        "try:\n",
        "    loader = UniversalLoader()\n",
        "except NameError:\n",
        "    raise RuntimeError(\"UniversalLoader is not defined. Run the evaluation cell first.\")\n",
        "\n",
        "system_data = loader.load_eagle(eagle_json)\n",
        "system_data.clip_name = f\"{MATCH_NAME}_clip_{CLIP_ID}\"\n",
        "\n",
        "print(\"System name:\", system_data.name)\n",
        "print(\"Number of frame entries in system_data.frames:\", len(system_data.frames))\n",
        "\n",
        "if system_data.frames:\n",
        "    frame_ids_loaded = sorted(system_data.frames.keys())\n",
        "    print(\"First 10 frame ids in loader:\", frame_ids_loaded[:10])\n",
        "\n",
        "    total_dets = sum(len(v) for v in system_data.frames.values())\n",
        "    print(\"Total detections (loader):\", total_dets)\n",
        "\n",
        "    unique_tracks = sorted({d.track_id for lst in system_data.frames.values() for d in lst})\n",
        "    print(\"Number of unique tracks:\", len(unique_tracks))\n",
        "    print(\"Sample of track_ids:\", unique_tracks[:20])\n",
        "\n",
        "print(\"\\n=== EVALUATOR METRICS FOR THIS CLIP (EAGLE ONLY) ===\")\n",
        "try:\n",
        "    evaluator = TrackingEvaluator()\n",
        "    metrics = evaluator.evaluate_system(system_data)\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "except NameError:\n",
        "    print(\"TrackingEvaluator not defined. Run the evaluation cell first.\")\n"
      ],
      "metadata": {
        "id": "dsnEjpBL8Ilc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Download results\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print_status(\"Creating archive...\", \"INFO\")\n",
        "\n",
        "archive_name = \"tracking_results\"\n",
        "archive_path = BASE_DIR / archive_name\n",
        "\n",
        "shutil.make_archive(str(archive_path), 'zip', OUTPUT_DIR)\n",
        "\n",
        "print_status(\"Downloading...\", \"SUCCESS\")\n",
        "files.download(f\"{archive_path}.zip\")\n",
        "\n",
        "print_status(\"Complete!\", \"SUCCESS\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
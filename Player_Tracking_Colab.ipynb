{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Player Tracking System Comparison\n",
        "\n",
        "This notebook compares 3 different player tracking systems:\n",
        "- Eagle\n",
        "- Darkmyter (using Ultralytics YOLO)\n",
        "- TrackLab\n",
        "\n",
        "**Important**: Run cells in order from top to bottom!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bed4526-df4e-4060-f6e8-27b132679858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Directory structure created\u001b[0m\n",
            "Working directory: /content\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup directories and utilities\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "BASE_DIR = Path(\"/content\")\n",
        "REPOS_DIR = BASE_DIR / \"repositories\"\n",
        "VIDEOS_DIR = BASE_DIR / \"videos\"\n",
        "CLIPS_DIR = BASE_DIR / \"clips\"\n",
        "OUTPUT_DIR = BASE_DIR / \"output\"\n",
        "\n",
        "for d in [REPOS_DIR, VIDEOS_DIR, CLIPS_DIR, OUTPUT_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def print_status(msg, status=\"INFO\"):\n",
        "    \"\"\"Print colored status messages\"\"\"\n",
        "    colors = {\n",
        "        \"INFO\": \"\\033[94m\",\n",
        "        \"SUCCESS\": \"\\033[92m\",\n",
        "        \"WARNING\": \"\\033[93m\",\n",
        "        \"ERROR\": \"\\033[91m\",\n",
        "        \"RESET\": \"\\033[0m\"\n",
        "    }\n",
        "    print(f\"{colors.get(status, '')}[{status}] {msg}{colors['RESET']}\")\n",
        "\n",
        "print_status(\"Directory structure created\", \"SUCCESS\")\n",
        "print(f\"Working directory: {BASE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04192215-0ffb-4dce-ffde-e581a5e085d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Cloning repositories...\u001b[0m\n",
            "\u001b[94m[INFO] eagle: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] eagle: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] darkmyter: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] darkmyter: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] tracklab: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] tracklab: Cloned successfully\u001b[0m\n",
            "\u001b[92m[SUCCESS] Repository cloning complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Clone all repositories\n",
        "\n",
        "import subprocess\n",
        "\n",
        "REPOSITORIES = {\n",
        "    \"eagle\": \"https://github.com/nreHieW/Eagle.git\",\n",
        "    \"darkmyter\": \"https://github.com/Darkmyter/Football-Players-Tracking.git\",\n",
        "}\n",
        "\n",
        "print_status(\"Cloning repositories...\", \"INFO\")\n",
        "\n",
        "for name, url in REPOSITORIES.items():\n",
        "    repo_path = REPOS_DIR / name\n",
        "\n",
        "    if repo_path.exists():\n",
        "        print_status(f\"{name}: Already exists, skipping\", \"WARNING\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        print_status(f\"{name}: Cloning...\", \"INFO\")\n",
        "        result = subprocess.run(\n",
        "            [\"git\", \"clone\", url, str(repo_path)],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=300\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print_status(f\"{name}: Cloned successfully\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"{name}: Clone failed - {result.stderr[:100]}\", \"ERROR\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{name}: Clone failed - {str(e)}\", \"ERROR\")\n",
        "\n",
        "print_status(\"Repository cloning complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556b566a-2daa-4634-adf6-df4bf48b9b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Installing dependencies...\u001b[0m\n",
            "\u001b[92m[SUCCESS] Dependencies installed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Install dependencies\n",
        "\n",
        "print_status(\"Installing dependencies...\", \"INFO\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio tracklab\n",
        "!pip install -q opencv-python numpy scipy pandas scikit-learn matplotlib\n",
        "!pip install -q ultralytics supervision\n",
        "!pip install -q gdown Pillow tqdm requests\n",
        "\n",
        "print_status(\"Dependencies installed\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_videos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4dfaeb5-a607-4bde-aac9-6e765184b5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Downloading videos from shared folder...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4\n",
            "Processing file 1RvqkxASOD23jfigqSgSgGja5_NGZReO4 FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\n",
            "Processing file 1urwKF6wjitkREymiNi9O3jCLLIysTp6F FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf\n",
            "From (redirected): https://drive.google.com/uc?id=1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf&confirm=t&uuid=eac5e386-ae9a-4914-a545-2df267f48772\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4\n",
            "100%|██████████| 1.68G/1.68G [00:17<00:00, 97.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RvqkxASOD23jfigqSgSgGja5_NGZReO4\n",
            "From (redirected): https://drive.google.com/uc?id=1RvqkxASOD23jfigqSgSgGja5_NGZReO4&confirm=t&uuid=7cbcbc67-bfda-4454-9a6d-0a96920ea70b\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\n",
            "100%|██████████| 1.92G/1.92G [00:18<00:00, 105MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1urwKF6wjitkREymiNi9O3jCLLIysTp6F\n",
            "From (redirected): https://drive.google.com/uc?id=1urwKF6wjitkREymiNi9O3jCLLIysTp6F&confirm=t&uuid=75d4854f-3780-4410-bb3b-819ef12c425c\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4\n",
            "100%|██████████| 1.32G/1.32G [00:13<00:00, 96.9MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOWNLOADED 3 VIDEO(S)\n",
            "1. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4 (1260.8 MB)\n",
            "2. FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4 (1832.4 MB)\n",
            "3. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4 (1604.1 MB)\n",
            "Enter video selection:\n",
            "  - Leave blank to process ALL videos\n",
            "  - Enter a number (e.g., '1')\n",
            "  - Enter comma-separated numbers (e.g., '1,2')\n",
            "\n",
            "Your choice: 2\n",
            "\u001b[92m[SUCCESS] Selected: FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Download videos from Google Drive\n",
        "\n",
        "!pip install -q gdown\n",
        "\n",
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "# Shared folder ID\n",
        "FOLDER_ID = \"1Cs4kTX6GYwfcpKyDZdqRKBezz49wT7_N\"\n",
        "\n",
        "print_status(\"Downloading videos from shared folder...\", \"INFO\")\n",
        "\n",
        "try:\n",
        "    gdown.download_folder(\n",
        "        id=FOLDER_ID,\n",
        "        output=str(VIDEOS_DIR),\n",
        "        quiet=False,\n",
        "        use_cookies=False\n",
        "    )\n",
        "\n",
        "    # List downloaded videos\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.MP4', '.AVI', '.MOV', '.MKV']\n",
        "    available_videos = []\n",
        "\n",
        "    for ext in video_extensions:\n",
        "        available_videos.extend(list(VIDEOS_DIR.glob(f\"*{ext}\")))\n",
        "\n",
        "    if not available_videos:\n",
        "        print_status(\"No video files found\", \"ERROR\")\n",
        "    else:\n",
        "        print(f\"DOWNLOADED {len(available_videos)} VIDEO(S)\")\n",
        "\n",
        "\n",
        "        for idx, video in enumerate(available_videos, 1):\n",
        "            size_mb = video.stat().st_size / (1024 * 1024)\n",
        "            print(f\"{idx}. {video.name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "\n",
        "        print(\"Enter video selection:\")\n",
        "        print(\"  - Leave blank to process ALL videos\")\n",
        "        print(\"  - Enter a number (e.g., '1')\")\n",
        "        print(\"  - Enter comma-separated numbers (e.g., '1,2')\")\n",
        "\n",
        "        selection = input(\"\\nYour choice: \").strip()\n",
        "\n",
        "        VIDEO_PATHS = []\n",
        "\n",
        "        if not selection:\n",
        "            VIDEO_PATHS = available_videos\n",
        "            print_status(f\"Selected ALL {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "        elif selection.isdigit():\n",
        "            idx = int(selection)\n",
        "            if 1 <= idx <= len(available_videos):\n",
        "                VIDEO_PATHS = [available_videos[idx - 1]]\n",
        "                print_status(f\"Selected: {VIDEO_PATHS[0].name}\", \"SUCCESS\")\n",
        "        elif ',' in selection:\n",
        "            try:\n",
        "                indices = [int(x.strip()) for x in selection.split(',')]\n",
        "                for idx in indices:\n",
        "                    if 1 <= idx <= len(available_videos):\n",
        "                        VIDEO_PATHS.append(available_videos[idx - 1])\n",
        "                print_status(f\"Selected {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "            except ValueError:\n",
        "                print_status(\"Invalid input\", \"ERROR\")\n",
        "\n",
        "        if not VIDEO_PATHS:\n",
        "            print_status(\"No videos selected\", \"ERROR\")\n",
        "\n",
        "except Exception as e:\n",
        "    print_status(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "    print(\"\\nNote: Make sure the folder is set to 'Anyone with the link can view'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_clips",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a65751d-e2f4-4d69-db52-a3dc9f16904e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROCESSING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "\n",
            "Duration: 6258.0s | FPS: 50.0 | Frames: 312900\n",
            "\u001b[92m[SUCCESS] Clip 'start' extracted\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' extracted\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' extracted\u001b[0m\n",
            "\n",
            "Total: 3 clips from 1 video(s)\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Extract clips\n",
        "\n",
        "import cv2\n",
        "\n",
        "CLIP_DURATION = 60\n",
        "ALL_CLIPS = {}\n",
        "\n",
        "for VIDEO_PATH in VIDEO_PATHS:\n",
        "    VIDEO_NAME = VIDEO_PATH.stem\n",
        "\n",
        "\n",
        "    print(f\"PROCESSING: {VIDEO_NAME}\\n\")\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Duration: {duration:.1f}s | FPS: {fps:.1f} | Frames: {total_frames}\")\n",
        "\n",
        "    if duration < CLIP_DURATION * 3:\n",
        "        if duration < CLIP_DURATION:\n",
        "            CLIPS = [(0, duration, \"full\")]\n",
        "        else:\n",
        "            CLIPS = [(0, CLIP_DURATION, \"start\"), (max(duration - CLIP_DURATION, 0), CLIP_DURATION, \"end\")]\n",
        "    else:\n",
        "        CLIPS = [\n",
        "            (0, CLIP_DURATION, \"start\"),\n",
        "            ((duration - CLIP_DURATION) / 2, CLIP_DURATION, \"middle\"),\n",
        "            (duration - CLIP_DURATION, CLIP_DURATION, \"end\")\n",
        "        ]\n",
        "\n",
        "    CLIP_PATHS = {}\n",
        "\n",
        "    for start_time, clip_dur, position in CLIPS:\n",
        "        clip_name = f\"{VIDEO_NAME}_{position}.mp4\"\n",
        "        clip_path = CLIPS_DIR / clip_name\n",
        "\n",
        "        cmd = [\"ffmpeg\", \"-i\", str(VIDEO_PATH), \"-ss\", str(start_time), \"-t\", str(clip_dur),\n",
        "               \"-c\", \"copy\", str(clip_path), \"-y\", \"-loglevel\", \"error\"]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "        if result.returncode == 0 and clip_path.exists():\n",
        "            CLIP_PATHS[position] = clip_path\n",
        "            print_status(f\"Clip '{position}' extracted\", \"SUCCESS\")\n",
        "\n",
        "    ALL_CLIPS[VIDEO_NAME] = CLIP_PATHS\n",
        "\n",
        "print(f\"\\nTotal: {sum(len(clips) for clips in ALL_CLIPS.values())} clips from {len(VIDEO_PATHS)} video(s)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell: Setup Darkmyter (ByteTrack + YOLO)\n",
        "\n",
        "print_status(\"Setting up Darkmyter tracking...\", \"INFO\")\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "darkmyter_dir = REPOS_DIR / \"darkmyter\"\n",
        "\n",
        "# Download football-specific weights\n",
        "weights_dir = darkmyter_dir / \"yolov8-weights\"\n",
        "weights_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "custom_weights = weights_dir / \"yolov8l-football-players.pt\"\n",
        "gdrive_id = \"12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\"\n",
        "\n",
        "def download_darkmyter_weights():\n",
        "    print_status(\"Downloading Darkmyter football weights...\", \"INFO\")\n",
        "    try:\n",
        "        try:\n",
        "            import gdown\n",
        "        except ImportError:\n",
        "            subprocess.run([\"pip\", \"install\", \"gdown\"], check=True)\n",
        "            import gdown\n",
        "\n",
        "        url = f\"https://drive.google.com/uc?id={gdrive_id}\"\n",
        "        gdown.download(url, str(custom_weights), quiet=False)\n",
        "        print_status(\"Darkmyter weights downloaded\", \"SUCCESS\")\n",
        "    except Exception as e:\n",
        "        print_status(f\"Failed to download weights: {e}\", \"ERROR\")\n",
        "\n",
        "# Check if weights exist and are valid\n",
        "if custom_weights.exists():\n",
        "    try:\n",
        "        with open(custom_weights, \"rb\") as f:\n",
        "            header = f.read(16)\n",
        "        if header.startswith(b\"<\"):\n",
        "            print_status(\"Weights file is HTML, re-downloading...\", \"ERROR\")\n",
        "            custom_weights.unlink(missing_ok=True)\n",
        "            download_darkmyter_weights()\n",
        "        else:\n",
        "            print_status(\"Darkmyter weights already present\", \"SUCCESS\")\n",
        "    except Exception:\n",
        "        custom_weights.unlink(missing_ok=True)\n",
        "        download_darkmyter_weights()\n",
        "else:\n",
        "    download_darkmyter_weights()\n",
        "\n",
        "# Create corrected Darkmyter wrapper\n",
        "darkmyter_wrapper = darkmyter_dir / \"run_darkmyter.py\"\n",
        "darkmyter_wrapper.write_text('''\n",
        "import argparse\n",
        "import json\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    import torch\n",
        "except ImportError:\n",
        "    print(\"Error: ultralytics not installed\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--video\", required=True)\n",
        "    parser.add_argument(\"--output\", required=True)\n",
        "    parser.add_argument(\"--conf\", type=float, default=0.3)\n",
        "    parser.add_argument(\"--iou\", type=float, default=0.5)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: Video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(f\"Running Darkmyter Football-Specific Tracking:\", file=sys.stderr)\n",
        "\n",
        "    # Load football-specific model\n",
        "    repo_root = Path(__file__).resolve().parent\n",
        "    custom_weights = repo_root / \"yolov8-weights\" / \"yolov8l-football-players.pt\"\n",
        "\n",
        "    if custom_weights.exists():\n",
        "        print(f\"  ✓ Using football-specific weights\", file=sys.stderr)\n",
        "        model = YOLO(str(custom_weights))\n",
        "        using_custom = True\n",
        "    else:\n",
        "        print(f\"  ✗ Football weights not found, using generic\", file=sys.stderr)\n",
        "        model = YOLO(\"yolov8x.pt\")\n",
        "        using_custom = False\n",
        "\n",
        "    print(f\"  ✓ ByteTrack optimized for football\", file=sys.stderr)\n",
        "    print(f\"  ✓ Dual-threshold detection strategy\", file=sys.stderr)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"  Device: {device}\", file=sys.stderr)\n",
        "\n",
        "    # Run tracking with ByteTrack (Darkmyter's chosen tracker)\n",
        "    results = model.track(\n",
        "        source=str(video_path),\n",
        "        tracker=\"bytetrack.yaml\",\n",
        "        conf=args.conf,\n",
        "        iou=args.iou,\n",
        "        persist=True,\n",
        "        verbose=False,\n",
        "        device=device\n",
        "    )\n",
        "     # Collect \"raw\" YOLO results as JSON per frame\n",
        "    raw_frames = []\n",
        "    for frame_idx, r in enumerate(results_gen):\n",
        "        # r.tojson() returns a JSON string for this frame's predictions/tracks\n",
        "        try:\n",
        "            frame_obj = json.loads(r.tojson())\n",
        "        except Exception:\n",
        "            # Fallback: store raw JSON string if parsing fails\n",
        "            frame_obj = {\"frame_index\": frame_idx, \"raw_json\": r.tojson()}\n",
        "\n",
        "        # Ensure frame index is present\n",
        "        if isinstance(frame_obj, dict):\n",
        "            frame_obj.setdefault(\"frame_index\", frame_idx)\n",
        "\n",
        "        raw_frames.append(frame_obj)\n",
        "\n",
        "        if frame_idx % 100 == 0:\n",
        "            print(f\"Processed {frame_idx} frames...\", file=sys.stderr)\n",
        "\n",
        "    # Package minimal metadata + raw frames (no extra stats, no reformatting boxes)\n",
        "    darkmyter_raw = {\n",
        "        \"framework\": \"Darkmyter\",\n",
        "        \"backend\": \"Ultralytics YOLOv8\",\n",
        "        \"weights\": model_name,\n",
        "        \"tracker\": \"ByteTrack (bytetrack.yaml)\",\n",
        "        \"football_specific_weights\": football_specific,\n",
        "        \"device\": device,\n",
        "        \"conf\": args.conf,\n",
        "        \"iou\": args.iou,\n",
        "        \"video_path\": str(video_path),\n",
        "        \"num_frames\": len(raw_frames),\n",
        "        \"frames\": raw_frames,\n",
        "    }\n",
        "\n",
        "    # Save everything exactly where the evaluator expects\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with output_path.open(\"w\") as f:\n",
        "        json.dump(darkmyter_raw, f, indent=2)\n",
        "\n",
        "    print(\"\\\\nDarkmyter raw output saved to:\", file=sys.stderr)\n",
        "    print(f\"  {output_path}\", file=sys.stderr)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "darkmyter_wrapper.chmod(0o755)\n",
        "print_status(\"Darkmyter full capability wrapper created\", \"SUCCESS\")"
      ],
      "metadata": {
        "id": "H_etsZN8K1QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0197b418-d674-447a-b1eb-1a45feac3239",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Darkmyter tracking...\u001b[0m\n",
            "\u001b[94m[INFO] Downloading Darkmyter football weights...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\n",
            "From (redirected): https://drive.google.com/uc?id=12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx&confirm=t&uuid=66e07bd6-70fe-4f8e-85da-14e48e693ddb\n",
            "To: /content/repositories/darkmyter/yolov8-weights/yolov8l-football-players.pt\n",
            "100%|██████████| 87.6M/87.6M [00:01<00:00, 59.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Darkmyter weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Darkmyter full capability wrapper created\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell: Setup Eagle with Python 3.13\n",
        "\n",
        "print_status(\"Setting up Eagle with Python 3.13...\", \"INFO\")\n",
        "\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "# Install Python 3.13 (Eagle's required version)\n",
        "print_status(\"Installing Python 3.13...\", \"INFO\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y software-properties-common\n",
        "!add-apt-repository -y ppa:deadsnakes/ppa\n",
        "!apt-get update -qq\n",
        "!apt-get install -y python3.13 python3.13-venv python3.13-dev python3.13-distutils\n",
        "\n",
        "# Install pip for Python 3.13\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.13\n",
        "\n",
        "# Install uv if not already installed\n",
        "print_status(\"Installing uv...\", \"INFO\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "\n",
        "# Add uv to PATH\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/.local/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# Create Eagle environment with Python 3.13\n",
        "os.chdir(eagle_dir)\n",
        "print_status(\"Creating Eagle environment with Python 3.13...\", \"INFO\")\n",
        "!uv venv --python python3.13\n",
        "!uv sync\n",
        "\n",
        "# Download model weights\n",
        "print_status(\"Downloading Eagle model weights...\", \"INFO\")\n",
        "models_dir = eagle_dir / \"eagle\" / \"models\"\n",
        "if models_dir.exists():\n",
        "    os.chdir(models_dir)\n",
        "    !bash get_weights.sh\n",
        "    os.chdir(eagle_dir)\n",
        "    print_status(\"Eagle weights downloaded\", \"SUCCESS\")\n",
        "else:\n",
        "    print_status(\"Eagle models directory not found\", \"ERROR\")\n",
        "\n",
        "# Create Eagle wrapper that uses Python 3.13\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "eagle_wrapper.write_text('''\n",
        "import argparse\n",
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--video\", required=True)\n",
        "    parser.add_argument(\"--output\", required=True)\n",
        "    parser.add_argument(\"--fps\", default=10, type=int)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: Video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Set up environment\n",
        "    env = os.environ.copy()\n",
        "    env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "    # Run Eagle with Python 3.13 - FULL PIPELINE\n",
        "    cmd = [\n",
        "        \"uv\", \"run\", \"--python\", \"python3.13\",\n",
        "        \"main.py\",\n",
        "        \"--video_path\", str(video_path),\n",
        "        \"--fps\", str(args.fps),\n",
        "    ]\n",
        "\n",
        "    print(f\"Processing {video_path} at {args.fps} FPS...\", file=sys.stderr)\n",
        "    start = time.time()\n",
        "\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        cwd=Path(__file__).parent,\n",
        "        timeout=600,  # 10 minute timeout\n",
        "        env=env,\n",
        "    )\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"Eagle processing took {elapsed:.1f}s ({elapsed/60:.1f} minutes)\", file=sys.stderr)\n",
        "\n",
        "    # Log errors but keep going so we can at least copy whatever exists\n",
        "    if result.returncode != 0:\n",
        "        print(f\"[Eagle] warnings/errors (continuing anyway): {result.stderr[:500]}\", file=sys.stderr)\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # Copy RAW Eagle output into the requested folder\n",
        "    # ---------------------------------------------------\n",
        "    video_stem = video_path.stem\n",
        "    eagle_base = Path(__file__).parent / \"output\"\n",
        "\n",
        "    # 1) Locate Eagle's internal output folder for this video\n",
        "    eagle_output_dir = eagle_base / video_stem\n",
        "    if not eagle_output_dir.exists():\n",
        "        # fallback: any subdir containing the video stem\n",
        "        for d in eagle_base.iterdir():\n",
        "            if d.is_dir() and video_stem in d.name:\n",
        "                eagle_output_dir = d\n",
        "                break\n",
        "\n",
        "    if not eagle_output_dir.exists():\n",
        "        print(f\"[Eagle] Could not find internal output folder for {video_stem}\", file=sys.stderr)\n",
        "        # Still create an empty file so the pipeline doesn't crash\n",
        "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with output_path.open(\"w\") as f:\n",
        "            json.dump([], f)\n",
        "        sys.exit(0)\n",
        "\n",
        "    # 2) If Eagle uses raw_coordinates/, descend there\n",
        "    coords_root = eagle_output_dir / \"raw_coordinates\"\n",
        "    if coords_root.exists():\n",
        "        source_root = coords_root\n",
        "    else:\n",
        "        source_root = eagle_output_dir\n",
        "\n",
        "    print(f\"[Eagle] Copying raw outputs from {source_root}\", file=sys.stderr)\n",
        "\n",
        "    # 3) Copy all .json files into the requested output folder\n",
        "    target_dir = output_path.parent\n",
        "    target_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    copied_files = []\n",
        "    for src in sorted(source_root.glob(\"*.json\")):\n",
        "        dst = target_dir / src.name\n",
        "        shutil.copy2(src, dst)\n",
        "        copied_files.append(dst.name)\n",
        "\n",
        "    print(f\"[Eagle] Copied JSON files: {copied_files}\", file=sys.stderr)\n",
        "\n",
        "    # 4) Choose one \"canonical\" file as output.json (no modification)\n",
        "    processed = source_root / \"processed_data.json\"\n",
        "    if processed.exists():\n",
        "        shutil.copy2(processed, output_path)\n",
        "        print(f\"[Eagle] Using processed_data.json as output.json\", file=sys.stderr)\n",
        "    else:\n",
        "        any_json = next(source_root.glob(\"*.json\"), None)\n",
        "        if any_json is not None:\n",
        "            shutil.copy2(any_json, output_path)\n",
        "            print(f\"[Eagle] Using {any_json.name} as output.json\", file=sys.stderr)\n",
        "        else:\n",
        "            # No JSONs found: write an empty list to keep the pipeline alive\n",
        "            with output_path.open(\"w\") as f:\n",
        "                json.dump([], f)\n",
        "            print(f\"[Eagle] No JSON files found, wrote empty output.json\", file=sys.stderr)\n",
        "\n",
        "    sys.exit(0)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "eagle_wrapper.chmod(0o755)\n",
        "print_status(\"Eagle FULL capability wrapper created\", \"SUCCESS\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIMyv7HMfsbb",
        "outputId": "645ec57f-3ab2-4ed7-aeb7-b541e6b95c31",
        "collapsed": true
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Eagle with Python 3.13...\u001b[0m\n",
            "\u001b[94m[INFO] Installing Python 3.13...\u001b[0m\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Repository: 'deb https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu/ jammy main'\n",
            "Description:\n",
            "This PPA contains more recent Python versions packaged for Ubuntu.\n",
            "\n",
            "Disclaimer: there's no guarantee of timely updates in case of security problems or other issues. If you want to use them in a security-or-otherwise-critical environment (say, on a production server), you do so at your own risk.\n",
            "\n",
            "Update Note\n",
            "===========\n",
            "Please use this repository instead of ppa:fkrull/deadsnakes.\n",
            "\n",
            "Reporting Issues\n",
            "================\n",
            "\n",
            "Issues can be reported in the master issue tracker at:\n",
            "https://github.com/deadsnakes/issues/issues\n",
            "\n",
            "Supported Ubuntu and Python Versions\n",
            "====================================\n",
            "\n",
            "- Ubuntu 22.04 (jammy) Python3.7 - Python3.9, Python3.11 - Python3.13\n",
            "- Ubuntu 24.04 (noble) Python3.7 - Python3.11, Python3.13\n",
            "- Note: Python 3.10 (jammy), Python3.12 (noble) are not provided by deadsnakes as upstream ubuntu provides those packages.\n",
            "\n",
            "Why some packages aren't built:\n",
            "- Note: for jammy and noble, older python versions requre libssl<3 so they are not currently built\n",
            "- If you need these, reach out to asottile to set up a private ppa\n",
            "\n",
            "The packages may also work on other versions of Ubuntu or Debian, but that is not tested or supported.\n",
            "\n",
            "Packages\n",
            "========\n",
            "\n",
            "The packages provided here are loosely based on the debian upstream packages with some modifications to make them more usable as non-default pythons and on ubuntu.  As such, the packages follow debian's patterns and often do not include a full python distribution with just `apt install python#.#`.  Here is a list of packages that may be useful along with the default install:\n",
            "\n",
            "- `python#.#-dev`: includes development headers for building C extensions\n",
            "- `python#.#-venv`: provides the standard library `venv` module\n",
            "- `python#.#-distutils`: provides the standard library `distutils` module\n",
            "- `python#.#-lib2to3`: provides the `2to3-#.#` utility as well as the standard library `lib2to3` module\n",
            "- `python#.#-gdbm`: provides the standard library `dbm.gnu` module\n",
            "- `python#.#-tk`: provides the standard library `tkinter` module\n",
            "\n",
            "Third-Party Python Modules\n",
            "==========================\n",
            "\n",
            "Python modules in the official Ubuntu repositories are packaged to work with the Python interpreters from the official repositories. Accordingly, they generally won't work with the Python interpreters from this PPA. As an exception, pure-Python modules for Python 3 will work, but any compiled extension modules won't.\n",
            "\n",
            "To install 3rd-party Python modules, you should use the common Python packaging tools.  For an introduction into the Python packaging ecosystem and its tools, refer to the Python Packaging User Guide:\n",
            "https://packaging.python.org/installing/\n",
            "\n",
            "Sources\n",
            "=======\n",
            "The package sources are available at:\n",
            "https://github.com/deadsnakes/\n",
            "\n",
            "Nightly Builds\n",
            "==============\n",
            "\n",
            "For nightly builds, see ppa:deadsnakes/nightly https://launchpad.net/~deadsnakes/+archive/ubuntu/nightly\n",
            "More info: https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa\n",
            "Adding repository.\n",
            "Found existing deb entry in /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding deb entry to /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Found existing deb-src entry in /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/deadsnakes-ubuntu-ppa.gpg with fingerprint F23C5A6CF475977595C89F51BA6932366A755776\n",
            "Get:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 3,917 B in 1s (3,215 B/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python3.13-distutils\n",
            "E: Couldn't find any package by glob 'python3.13-distutils'\n",
            "E: Couldn't find any package by regex 'python3.13-distutils'\n",
            "/bin/bash: line 1: python3.13: command not found\n",
            "curl: (23) Failure writing output to destination\n",
            "\u001b[94m[INFO] Installing uv...\u001b[0m\n",
            "downloading uv 0.9.11 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "\u001b[94m[INFO] Creating Eagle environment with Python 3.13...\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\n",
            "Using CPython \u001b[36m3.13.9\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[33m?\u001b[0m \u001b[1mA virtual environment already exists at `.venv`. Do you want to replace it?\u001b[0m \u001b[38;5;8m[y/n]\u001b[0m \u001b[38;5;8m›\u001b[0m \u001b[36myes\u001b[0m\n",
            "\n",
            "\u001b[0J\u001b[32m✔\u001b[0m \u001b[1mA virtual environment already exists at `.venv`. Do you want to replace it?\u001b[0m \u001b[38;5;8m·\u001b[0m \u001b[36myes\u001b[0m\n",
            "\u001b[?25hActivate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
            "\u001b[2mResolved \u001b[1m119 packages\u001b[0m \u001b[2min 0.88ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m113 packages\u001b[0m \u001b[2min 1.30s\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1malbucore\u001b[0m\u001b[2m==0.0.24\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1malbumentations\u001b[0m\u001b[2m==2.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbayesian-optimization\u001b[0m\u001b[2m==3.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.13.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mboxmot\u001b[0m\u001b[2m==15.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.19.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilterpy\u001b[0m\u001b[2m==1.4.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.59.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgdown\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.45\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.30.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlapx\u001b[0m\u001b[2m==0.5.11.post1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmplcursors\u001b[0m\u001b[2m==0.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmplsoccer\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python-headless\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpy-cpuinfo\u001b[0m\u001b[2m==9.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5\u001b[0m\u001b[2m==5.15.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5-qt5\u001b[0m\u001b[2m==5.15.17\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5-sip\u001b[0m\u001b[2m==12.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpysocks\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msimsimd\u001b[0m\u001b[2m==6.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstringzilla\u001b[0m\u001b[2m==3.12.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1multralytics\u001b[0m\u001b[2m==8.3.184\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1multralytics-thop\u001b[0m\u001b[2m==2.0.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1myacs\u001b[0m\u001b[2m==0.1.8\u001b[0m\n",
            "\u001b[94m[INFO] Downloading Eagle model weights...\u001b[0m\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI\n",
            "From (redirected): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI&confirm=t&uuid=14b970f6-0462-4209-aeda-3fb41c256a6a\n",
            "To: /content/repositories/eagle/eagle/models/weights.zip\n",
            "100% 821M/821M [00:09<00:00, 89.6MB/s]\n",
            "Archive:  weights.zip\n",
            "replace weights/detector_large_hd.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "\u001b[92m[SUCCESS] Eagle weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Eagle FULL capability wrapper created\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "REPOS_DIR = Path(\"/content/repositories\")\n",
        "ultra_dir = REPOS_DIR / \"ultra_trackers\"\n",
        "ultra_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "runner_script = ultra_dir / \"run_ultra_yolo_tracker.py\"\n",
        "runner_script.write_text(textwrap.dedent(\"\"\"\\\n",
        "    #!/usr/bin/env python\n",
        "    \\\"\\\"\\\"Run Ultralytics YOLO (v5 or v8 weights) with a chosen tracker and dump JSON tracks.\n",
        "\n",
        "    Usage:\n",
        "      python run_ultra_yolo_tracker.py \\\\\n",
        "          --video input.mp4 \\\\\n",
        "          --output output.json \\\\\n",
        "          --weights yolov5s.pt \\\\\n",
        "          --tracker botsort\n",
        "    \\\"\\\"\\\"\n",
        "\n",
        "    import argparse\n",
        "    import json\n",
        "    from pathlib import Path\n",
        "\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "\n",
        "    def main():\n",
        "        parser = argparse.ArgumentParser(description=\"YOLO + tracker to JSON\")\n",
        "        parser.add_argument(\"--video\", required=True, help=\"Path to input video\")\n",
        "        parser.add_argument(\"--output\", required=True, help=\"Path to output JSON\")\n",
        "        parser.add_argument(\"--weights\", default=\"yolov5s.pt\",\n",
        "                            help=\"YOLO weights (e.g., yolov5s.pt, yolov5m.pt, yolov8n.pt, ...)\")\n",
        "        parser.add_argument(\"--tracker\", default=\"botsort\",\n",
        "                            choices=[\"botsort\", \"deepsort\", \"bytetrack\"],\n",
        "                            help=\"Which tracker config to use\")\n",
        "        parser.add_argument(\"--conf\", type=float, default=0.3,\n",
        "                            help=\"Confidence threshold\")\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        video_path = Path(args.video)\n",
        "        out_path = Path(args.output)\n",
        "\n",
        "        # Load YOLO model (Ultralytics supports yolov5*.pt weights too)\n",
        "        model = YOLO(args.weights)\n",
        "\n",
        "        # Ultralytics resolves built-in tracker configs like 'botsort.yaml'\n",
        "        tracker_cfg = f\"{args.tracker}.yaml\"\n",
        "\n",
        "        # Run tracking; stream=True yields a generator of per-frame Results\n",
        "        results = model.track(\n",
        "            source=str(video_path),\n",
        "            tracker=tracker_cfg,\n",
        "            conf=args.conf,\n",
        "            iou=0.5,\n",
        "            stream=True,\n",
        "            device=0,       # use GPU 0 if available, otherwise falls back to CPU\n",
        "            save=False,\n",
        "            verbose=False,\n",
        "        )\n",
        "        print(\"YOLO model device after track:\", model.device)\n",
        "\n",
        "        all_detections = []\n",
        "        frame_idx = 0\n",
        "\n",
        "        for r in results:\n",
        "            boxes = r.boxes\n",
        "            if boxes is None:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            # Tracker output: each box has xyxy, conf, cls, id\n",
        "            ids = boxes.id\n",
        "            if ids is None:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            xyxy = boxes.xyxy\n",
        "            confs = boxes.conf\n",
        "            clses = boxes.cls\n",
        "\n",
        "            ids = ids.cpu().tolist()\n",
        "            xyxy = xyxy.cpu().tolist()\n",
        "            confs = confs.cpu().tolist()\n",
        "            clses = clses.cpu().tolist()\n",
        "\n",
        "            for tid, (x1, y1, x2, y2), score, c in zip(ids, xyxy, confs, clses):\n",
        "                all_detections.append({\n",
        "                    \"frame_id\": frame_idx,\n",
        "                    \"track_id\": int(tid),\n",
        "                    \"bbox\": [float(x1), float(y1), float(x2), float(y2)],\n",
        "                    \"score\": float(score),\n",
        "                    \"class_id\": int(c),\n",
        "                })\n",
        "\n",
        "            frame_idx += 1\n",
        "\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with out_path.open(\"w\") as f:\n",
        "            json.dump(all_detections, f)\n",
        "\n",
        "        print(f\"Wrote {len(all_detections)} tracked detections to {out_path}\")\n",
        "\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        main()\n",
        "    \"\"\"))\n",
        "\n",
        "runner_script.chmod(0o755)\n",
        "print(\"Created\", runner_script)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I5iE6qiWWTy",
        "outputId": "694c966e-8168-44d5-8b11-7f633b6d4da4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created /content/repositories/ultra_trackers/run_ultra_yolo_tracker.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell: Final System Evaluation\n",
        "# ================================\n",
        "\n",
        "import time\n",
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\"\"\"SYSTEM_CONFIGS = {\n",
        "      \"eagle\": {\n",
        "        \"path\": REPOS_DIR / \"eagle\",\n",
        "        \"script\": \"run_eagle.py\",\n",
        "        \"python\": \"python3.13\",\n",
        "    },\n",
        "    \"darkmyter\": {\n",
        "        \"path\": REPOS_DIR / \"darkmyter\",\n",
        "        \"script\": \"run_darkmyter.py\",\n",
        "    },\n",
        "    \"yolov8_botsort\": {\n",
        "        \"path\": REPOS_DIR / \"ultra_trackers\",\n",
        "        \"script\": \"run_ultra_yolo_tracker.py\",\n",
        "        \"args\": [\"--weights\", \"yolov8m.pt\", \"--tracker\", \"botsort\"],\n",
        "    },\n",
        "    \"yolov5_bytetrack\": {\n",
        "        \"path\": REPOS_DIR / \"ultra_trackers\",\n",
        "        \"script\": \"run_ultra_yolo_tracker.py\",\n",
        "        \"args\": [\"--weights\", \"yolov5m.pt\", \"--tracker\", \"bytetrack\"],\n",
        "    },\n",
        "}\n",
        "\"\"\"\n",
        "# System configurations\n",
        "SYSTEM_CONFIGS = {\n",
        "      \"eagle\": {\n",
        "        \"path\": REPOS_DIR / \"eagle\",\n",
        "        \"script\": \"run_eagle.py\",\n",
        "        \"python\": \"python3.13\",\n",
        "    },\n",
        "    \"darkmyter\": {\n",
        "        \"path\": REPOS_DIR / \"darkmyter\",\n",
        "        \"script\": \"run_darkmyter.py\",\n",
        "    },\n",
        "    \"yolov8_botsort\": {\n",
        "        \"path\": REPOS_DIR / \"ultra_trackers\",\n",
        "        \"script\": \"run_ultra_yolo_tracker.py\",\n",
        "        \"args\": [\"--weights\", \"yolov8m.pt\", \"--tracker\", \"botsort\"],\n",
        "    },\n",
        "    \"yolov5_bytetrack\": {\n",
        "        \"path\": REPOS_DIR / \"ultra_trackers\",\n",
        "        \"script\": \"run_ultra_yolo_tracker.py\",\n",
        "        \"args\": [\"--weights\", \"yolov5m.pt\", \"--tracker\", \"bytetrack\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "position_to_number = {\"start\": 1, \"middle\": 2, \"end\": 3, \"full\": 1}\n",
        "\n",
        "def run_system_on_clip(system_name, system_config, video_name, clip_number, clip_path):\n",
        "    \"\"\"Run a tracking system on a clip\"\"\"\n",
        "\n",
        "    output_dir = OUTPUT_DIR / video_name / \"clips\" / str(clip_number) / system_name\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print_status(f\"Running {system_name} on {video_name}/clip_{clip_number}...\", \"INFO\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    output_file = output_dir / \"output.json\"\n",
        "    system_path = system_config.get(\"path\", REPOS_DIR)\n",
        "\n",
        "    # Build command as before for non-TrackLab systems\n",
        "    if system_name == \"eagle\":\n",
        "        cmd = [\n",
        "            \"uv\", \"run\", \"--python\", system_config.get(\"python\", \"python3.13\"),\n",
        "            \"run_eagle.py\",\n",
        "            \"--video\", str(clip_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ]\n",
        "    else:\n",
        "        cmd = [\n",
        "            \"python\", system_config[\"script\"],\n",
        "            \"--video\", str(clip_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ]\n",
        "        for extra in system_config.get(\"args\", []):\n",
        "            cmd.append(str(extra))\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=600,\n",
        "            cwd=str(system_path),\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        if result.returncode == 0 and output_file.exists():\n",
        "            try:\n",
        "                with open(output_file) as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                if isinstance(data, list):\n",
        "                    num_detections = len(data)\n",
        "                elif isinstance(data, dict):\n",
        "                    num_detections = sum(\n",
        "                        len(dets) if isinstance(dets, list) else 0\n",
        "                        for dets in data.values()\n",
        "                    )\n",
        "                else:\n",
        "                    num_detections = 0\n",
        "\n",
        "                print_status(\n",
        "                    f\"{system_name}: SUCCESS - {num_detections} detections in {elapsed:.1f}s\",\n",
        "                    \"SUCCESS\"\n",
        "                )\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"time\": elapsed,\n",
        "                    \"output\": str(output_file),\n",
        "                    \"detections\": num_detections,\n",
        "                }\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print_status(f\"{system_name}: Invalid JSON\", \"ERROR\")\n",
        "                return {\"success\": False, \"time\": elapsed, \"error\": f\"Invalid JSON: {e}\"}\n",
        "        else:\n",
        "            error_msg = result.stderr[-500:] if result.stderr else \"Unknown error\"\n",
        "            print_status(f\"{system_name}: FAILED\", \"ERROR\")\n",
        "            print(f\"Error: {error_msg}\")\n",
        "            return {\"success\": False, \"time\": elapsed, \"error\": error_msg}\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print_status(f\"{system_name}: TIMEOUT\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": 600, \"error\": \"Timeout\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{system_name}: EXCEPTION - {str(e)}\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": time.time() - start_time, \"error\": str(e)}\n",
        "\n",
        "\n",
        "# Main evaluation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING EVALUATION\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for video_name, clip_paths in ALL_CLIPS.items():\n",
        "    print(f\"\\nVIDEO: {video_name}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    video_results = {}\n",
        "\n",
        "    for clip_position, clip_path in clip_paths.items():\n",
        "        clip_number = position_to_number.get(clip_position, 1)\n",
        "\n",
        "        print(f\"\\nProcessing clip {clip_number} ({clip_position})...\")\n",
        "        video_results[f\"clip_{clip_number}\"] = {}\n",
        "\n",
        "        for system_name, system_config in SYSTEM_CONFIGS.items():\n",
        "            result = run_system_on_clip(system_name, system_config, video_name, clip_number, clip_path)\n",
        "            video_results[f\"clip_{clip_number}\"][system_name] = result\n",
        "\n",
        "        successful = sum(1 for r in video_results[f\"clip_{clip_number}\"].values() if r[\"success\"])\n",
        "        total = len(video_results[f\"clip_{clip_number}\"])\n",
        "        print(f\"Clip summary: {successful}/{total} systems succeeded\")\n",
        "\n",
        "    all_results[video_name] = video_results\n",
        "\n",
        "    summary_file = OUTPUT_DIR / video_name / \"summary.json\"\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        json.dump(video_results, f, indent=2)\n",
        "\n",
        "overall_summary = OUTPUT_DIR / \"overall_summary.json\"\n",
        "with open(overall_summary, \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "# Final statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "system_stats = {sys: {\"success\": 0, \"total\": 0} for sys in SYSTEM_CONFIGS.keys()}\n",
        "\n",
        "for video_results in all_results.values():\n",
        "    for clip_results in video_results.values():\n",
        "        for system_name, result in clip_results.items():\n",
        "            system_stats[system_name][\"total\"] += 1\n",
        "            if result[\"success\"]:\n",
        "                system_stats[system_name][\"success\"] += 1\n",
        "\n",
        "print(\"\\nSystem Success Rates:\")\n",
        "for system_name, stats in system_stats.items():\n",
        "    if stats[\"total\"] > 0:\n",
        "        success_rate = (stats[\"success\"] / stats[\"total\"]) * 100\n",
        "        print(f\"  {system_name}: {stats['success']}/{stats['total']} ({success_rate:.1f}%)\")\n",
        "\n",
        "print(f\"\\nResults: {OUTPUT_DIR}\")\n",
        "print(f\"Summary: {overall_summary}\")\n",
        "\n",
        "# Cell 8: Display results\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"RESULTS SUMMARY \\n\")\n",
        "\n",
        "\n",
        "summary_data = []\n",
        "\n",
        "for video_name, clips in all_results.items():\n",
        "    for clip_key, systems in clips.items():\n",
        "        for system_name, result in systems.items():\n",
        "            summary_data.append({\n",
        "                \"Video\": video_name,\n",
        "                \"Clip\": clip_key,\n",
        "                \"System\": system_name,\n",
        "                \"Status\": \"Valid\" if result[\"success\"] else \"Invalid\",\n",
        "                \"Time (s)\": f\"{result['time']:.1f}\"\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(summary_data)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "total_runs = len(summary_data)\n",
        "successful_runs = sum(1 for row in summary_data if row[\"Status\"] == \"Valid\")\n",
        "\n",
        "\n",
        "print(f\"Success Rate: {successful_runs}/{total_runs} ({100*successful_runs/total_runs:.1f}%)\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "EMRXc5GpkG4d",
        "outputId": "92db96fb-24eb-4ea1-e8ed-60d120fd434f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STARTING EVALUATION\n",
            "============================================================\n",
            "\n",
            "\n",
            "VIDEO: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "========================================\n",
            "\n",
            "Processing clip 1 (start)...\n",
            "\u001b[94m[INFO] Running eagle on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n",
            "\u001b[92m[SUCCESS] eagle: SUCCESS - 0 detections in 132.6s\u001b[0m\n",
            "\u001b[94m[INFO] Running darkmyter on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n",
            "\u001b[92m[SUCCESS] darkmyter: SUCCESS - 57442 detections in 97.2s\u001b[0m\n",
            "\u001b[94m[INFO] Running yolov8_botsort on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n",
            "\u001b[92m[SUCCESS] yolov8_botsort: SUCCESS - 4717 detections in 111.4s\u001b[0m\n",
            "\u001b[94m[INFO] Running yolov5_bytetrack on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n",
            "\u001b[92m[SUCCESS] yolov5_bytetrack: SUCCESS - 2707 detections in 39.9s\u001b[0m\n",
            "Clip summary: 4/4 systems succeeded\n",
            "\n",
            "Processing clip 2 (middle)...\n",
            "\u001b[94m[INFO] Running eagle on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_2...\u001b[0m\n",
            "\u001b[92m[SUCCESS] eagle: SUCCESS - 0 detections in 156.3s\u001b[0m\n",
            "\u001b[94m[INFO] Running darkmyter on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_2...\u001b[0m\n",
            "\u001b[92m[SUCCESS] darkmyter: SUCCESS - 63806 detections in 105.2s\u001b[0m\n",
            "\u001b[94m[INFO] Running yolov8_botsort on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_2...\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1167919102.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msystem_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSYSTEM_CONFIGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_system_on_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mvideo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"clip_{clip_number}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msystem_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1167919102.py\u001b[0m in \u001b[0;36mrun_system_on_clip\u001b[0;34m(system_name, system_config, video_name, clip_number, clip_path)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         result = subprocess.run(\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "eagle_base = Path(\"/content/repositories/eagle/output\")\n",
        "for p in eagle_base.rglob(\"processed_data.json\"):\n",
        "    print(\"Found:\", p)\n",
        "    with open(p) as f:\n",
        "        data = json.load(f)\n",
        "    print(\"Type:\", type(data))\n",
        "    first = next(iter(data.values())) if isinstance(data, dict) else data[0]\n",
        "    print(\"Frame keys:\", first.keys())\n",
        "    print(\"Sample coords_video:\", first.get(\"Coordinates_video\") or first.get(\"coordinates_video\"))\n",
        "    break\n"
      ],
      "metadata": {
        "id": "JjWjJBU_igAc"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"torch version:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"device name:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSpAoLxLYBUP",
        "outputId": "fd335a95-013d-4fdf-86f5-f8c6fe6dd6fb"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.8.0+cu126\n",
            "cuda available: True\n",
            "device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell: Comprehensive Fair Comparison Framework\n",
        "# ================================\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "class ComprehensiveFairEvaluator:\n",
        "    \"\"\"\n",
        "    Fair evaluation that respects each system's design goals and unique features\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def evaluate_all_systems(self, all_results):\n",
        "        \"\"\"\n",
        "        Comprehensive evaluation that credits each system for what it actually provides\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"COMPREHENSIVE FAIR EVALUATION\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        # Load all data including system-specific outputs\n",
        "        system_data = self.load_comprehensive_data(all_results)\n",
        "\n",
        "        # 1. Common Metrics (All systems can be compared on these)\n",
        "        print(\"\\n1. COMMON TRACKING METRICS\")\n",
        "        print(\"-\" * 40)\n",
        "        common_metrics = self.evaluate_common_metrics(system_data)\n",
        "\n",
        "        # 2. System-Specific Strengths\n",
        "        print(\"\\n2. SYSTEM-SPECIFIC CAPABILITIES\")\n",
        "        print(\"-\" * 40)\n",
        "        specific_metrics = self.evaluate_system_specific(system_data)\n",
        "\n",
        "        # 3. Use Case Suitability\n",
        "        print(\"\\n3. USE CASE EVALUATION\")\n",
        "        print(\"-\" * 40)\n",
        "        use_case_scores = self.evaluate_use_cases(common_metrics, specific_metrics)\n",
        "\n",
        "        # 4. Final Fair Ranking\n",
        "        print(\"\\n4. CONTEXTUALIZED RANKINGS\")\n",
        "        print(\"-\" * 40)\n",
        "        self.compute_fair_rankings(common_metrics, specific_metrics, use_case_scores)\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def load_comprehensive_data(self, all_results):\n",
        "        \"\"\"Load both standard and system-specific outputs\"\"\"\n",
        "        system_data = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "        for video_name, clips_data in all_results.items():\n",
        "            for clip_key, systems_data in clips_data.items():\n",
        "                for system_name, result_data in systems_data.items():\n",
        "                    if result_data.get('success'):\n",
        "                        # Load standard format\n",
        "                        json_path = Path(result_data['output'])\n",
        "                        if json_path.exists():\n",
        "                            with open(json_path, 'r') as f:\n",
        "                                system_data[system_name][f\"{video_name}_{clip_key}\"][\"standard\"] = json.load(f)\n",
        "\n",
        "                        # Load system-specific format\n",
        "                        if system_name == \"eagle\":\n",
        "                            eagle_path = json_path.with_suffix('.eagle.json')\n",
        "                            if eagle_path.exists():\n",
        "                                with open(eagle_path, 'r') as f:\n",
        "                                    system_data[system_name][f\"{video_name}_{clip_key}\"][\"native\"] = json.load(f)\n",
        "\n",
        "                        elif system_name == \"tracklab\":\n",
        "                            tracklab_path = json_path.with_suffix('.tracklab.json')\n",
        "                            if tracklab_path.exists():\n",
        "                                with open(tracklab_path, 'r') as f:\n",
        "                                    system_data[system_name][f\"{video_name}_{clip_key}\"][\"native\"] = json.load(f)\n",
        "\n",
        "                        elif system_name == \"darkmyter\":\n",
        "                            darkmyter_path = json_path.with_suffix('.darkmyter.json')\n",
        "                            if darkmyter_path.exists():\n",
        "                                with open(darkmyter_path, 'r') as f:\n",
        "                                    system_data[system_name][f\"{video_name}_{clip_key}\"][\"native\"] = json.load(f)\n",
        "\n",
        "        return system_data\n",
        "\n",
        "    def evaluate_common_metrics(self, system_data):\n",
        "        \"\"\"Metrics all systems can be compared on\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for system_name, clips in system_data.items():\n",
        "            print(f\"\\n{system_name} (Common Metrics):\")\n",
        "\n",
        "            all_metrics = []\n",
        "            for clip_name, data in clips.items():\n",
        "                detections = data.get(\"standard\", [])\n",
        "                if isinstance(detections, dict) and \"detections\" in detections:\n",
        "                    detections = detections[\"detections\"]\n",
        "\n",
        "                if detections:\n",
        "                    metrics = {\n",
        "                        \"detection_count\": len(detections),\n",
        "                        \"unique_tracks\": len(set(d.get(\"track_id\", 0) for d in detections)),\n",
        "                        \"avg_confidence\": np.mean([d.get(\"score\", 1.0) for d in detections]),\n",
        "                        \"track_consistency\": self.calculate_track_consistency(detections),\n",
        "                        \"coverage\": self.calculate_coverage(detections)\n",
        "                    }\n",
        "                    all_metrics.append(metrics)\n",
        "\n",
        "            if all_metrics:\n",
        "                results[system_name] = {\n",
        "                    \"avg_detections\": np.mean([m[\"detection_count\"] for m in all_metrics]),\n",
        "                    \"avg_tracks\": np.mean([m[\"unique_tracks\"] for m in all_metrics]),\n",
        "                    \"avg_confidence\": np.mean([m[\"avg_confidence\"] for m in all_metrics]),\n",
        "                    \"track_consistency\": np.mean([m[\"track_consistency\"] for m in all_metrics]),\n",
        "                    \"coverage\": np.mean([m[\"coverage\"] for m in all_metrics])\n",
        "                }\n",
        "\n",
        "                print(f\"  Detections/clip: {results[system_name]['avg_detections']:.0f}\")\n",
        "                print(f\"  Unique tracks: {results[system_name]['avg_tracks']:.1f}\")\n",
        "                print(f\"  Confidence: {results[system_name]['avg_confidence']:.3f}\")\n",
        "                print(f\"  Consistency: {results[system_name]['track_consistency']:.3f}\")\n",
        "                print(f\"  Coverage: {results[system_name]['coverage']:.3f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_system_specific(self, system_data):\n",
        "        \"\"\"Evaluate unique capabilities of each system\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Eagle-specific: Tactical analysis features\n",
        "        if \"eagle\" in system_data:\n",
        "            print(f\"\\nEagle (Unique Capabilities):\")\n",
        "            eagle_features = {\n",
        "                \"has_homography\": False,\n",
        "                \"has_team_classification\": False,\n",
        "                \"has_pitch_coordinates\": False,\n",
        "                \"has_ball_tracking\": False,\n",
        "                \"processing_time\": []\n",
        "            }\n",
        "\n",
        "            for clip_name, data in system_data[\"eagle\"].items():\n",
        "                native = data.get(\"native\", {})\n",
        "                if \"eagle_features\" in native:\n",
        "                    features = native[\"eagle_features\"]\n",
        "                    eagle_features[\"has_homography\"] |= features.get(\"homography_matrix\") is not None\n",
        "                    eagle_features[\"has_team_classification\"] |= len(features.get(\"team_assignments\", {})) > 0\n",
        "                    eagle_features[\"has_pitch_coordinates\"] |= len(features.get(\"pitch_coordinates\", [])) > 0\n",
        "                    eagle_features[\"has_ball_tracking\"] |= len(features.get(\"ball_tracking\", [])) > 0\n",
        "\n",
        "                if \"video_info\" in native:\n",
        "                    eagle_features[\"processing_time\"].append(native[\"video_info\"].get(\"processing_time\", 0))\n",
        "\n",
        "            results[\"eagle\"] = eagle_features\n",
        "            print(f\"  ✓ Homography mapping: {eagle_features['has_homography']}\")\n",
        "            print(f\"  ✓ Team classification: {eagle_features['has_team_classification']}\")\n",
        "            print(f\"  ✓ Pitch coordinates: {eagle_features['has_pitch_coordinates']}\")\n",
        "            print(f\"  ✓ Ball tracking: {eagle_features['has_ball_tracking']}\")\n",
        "            if eagle_features[\"processing_time\"]:\n",
        "                print(f\"  Processing time: {np.mean(eagle_features['processing_time']):.1f}s\")\n",
        "\n",
        "        # TrackLab-specific: Modularity\n",
        "        if \"tracklab\" in system_data:\n",
        "            print(f\"\\nTrackLab (Unique Capabilities):\")\n",
        "            tracklab_features = {\n",
        "                \"modular_architecture\": True,\n",
        "                \"swappable_components\": True,\n",
        "                \"supported_detectors\": [\"yolov5\", \"yolov8\"],\n",
        "                \"supported_trackers\": [\"bytetrack\", \"botsort\", \"deepsort\"],\n",
        "                \"research_framework\": True\n",
        "            }\n",
        "            results[\"tracklab\"] = tracklab_features\n",
        "            print(f\"  ✓ Modular architecture: {tracklab_features['modular_architecture']}\")\n",
        "            print(f\"  ✓ Detectors: {', '.join(tracklab_features['supported_detectors'])}\")\n",
        "            print(f\"  ✓ Trackers: {', '.join(tracklab_features['supported_trackers'])}\")\n",
        "            print(f\"  ✓ Research framework: {tracklab_features['research_framework']}\")\n",
        "\n",
        "        # Darkmyter-specific: Football optimization\n",
        "        if \"darkmyter\" in system_data:\n",
        "            print(f\"\\nDarkmyter (Unique Capabilities):\")\n",
        "            darkmyter_features = {\n",
        "                \"football_specific_weights\": False,\n",
        "                \"optimized_for_speed\": True,\n",
        "                \"simple_integration\": True\n",
        "            }\n",
        "\n",
        "            for clip_name, data in system_data[\"darkmyter\"].items():\n",
        "                native = data.get(\"native\", {})\n",
        "                if \"features\" in native:\n",
        "                    darkmyter_features[\"football_specific_weights\"] |= native[\"features\"].get(\"football_specific\", False)\n",
        "\n",
        "            results[\"darkmyter\"] = darkmyter_features\n",
        "            print(f\"  ✓ Football-specific weights: {darkmyter_features['football_specific_weights']}\")\n",
        "            print(f\"  ✓ Speed optimized: {darkmyter_features['optimized_for_speed']}\")\n",
        "            print(f\"  ✓ Simple integration: {darkmyter_features['simple_integration']}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_use_cases(self, common_metrics, specific_metrics):\n",
        "        \"\"\"Score each system for different use cases\"\"\"\n",
        "        use_cases = {}\n",
        "\n",
        "        print(\"\\nUse Case Suitability Scores (0-100):\")\n",
        "\n",
        "        # Use Case 1: Real-time tracking\n",
        "        print(\"\\n  Real-time Tracking:\")\n",
        "        use_cases[\"realtime\"] = {}\n",
        "        for system in common_metrics.keys():\n",
        "            score = 0\n",
        "            score += common_metrics[system][\"avg_confidence\"] * 30\n",
        "            score += common_metrics[system][\"coverage\"] * 20\n",
        "\n",
        "            if system == \"darkmyter\":\n",
        "                score += 30  # Speed optimized\n",
        "            elif system == \"tracklab\":\n",
        "                score += 20  # Flexible but not speed-focused\n",
        "            elif system == \"eagle\":\n",
        "                score += 0   # Too slow for real-time\n",
        "\n",
        "            use_cases[\"realtime\"][system] = min(score, 100)\n",
        "            print(f\"    {system}: {use_cases['realtime'][system]:.1f}\")\n",
        "\n",
        "        # Use Case 2: Tactical analysis\n",
        "        print(\"\\n  Tactical Analysis:\")\n",
        "        use_cases[\"tactical\"] = {}\n",
        "        for system in common_metrics.keys():\n",
        "            score = 0\n",
        "            score += common_metrics[system][\"track_consistency\"] * 20\n",
        "\n",
        "            if system == \"eagle\" and system in specific_metrics:\n",
        "                eagle_feats = specific_metrics[\"eagle\"]\n",
        "                score += 20 if eagle_feats.get(\"has_homography\") else 0\n",
        "                score += 20 if eagle_feats.get(\"has_team_classification\") else 0\n",
        "                score += 20 if eagle_feats.get(\"has_pitch_coordinates\") else 0\n",
        "                score += 20 if eagle_feats.get(\"has_ball_tracking\") else 0\n",
        "            elif system == \"tracklab\":\n",
        "                score += 30  # Good tracking quality\n",
        "            elif system == \"darkmyter\":\n",
        "                score += 25  # Football-specific\n",
        "\n",
        "            use_cases[\"tactical\"][system] = min(score, 100)\n",
        "            print(f\"    {system}: {use_cases['tactical'][system]:.1f}\")\n",
        "\n",
        "        # Use Case 3: Research/Experimentation\n",
        "        print(\"\\n  Research & Development:\")\n",
        "        use_cases[\"research\"] = {}\n",
        "        for system in common_metrics.keys():\n",
        "            score = 0\n",
        "\n",
        "            if system == \"tracklab\" and system in specific_metrics:\n",
        "                score += 40  # Modular architecture\n",
        "                score += 30  # Multiple options\n",
        "                score += 20  # Research framework\n",
        "            elif system == \"eagle\":\n",
        "                score += 30  # Complex features\n",
        "            elif system == \"darkmyter\":\n",
        "                score += 20  # Simple baseline\n",
        "\n",
        "            score += common_metrics[system][\"avg_confidence\"] * 10\n",
        "\n",
        "            use_cases[\"research\"][system] = min(score, 100)\n",
        "            print(f\"    {system}: {use_cases['research'][system]:.1f}\")\n",
        "\n",
        "        return use_cases\n",
        "\n",
        "    def compute_fair_rankings(self, common_metrics, specific_metrics, use_case_scores):\n",
        "        \"\"\"Provide context-aware rankings\"\"\"\n",
        "\n",
        "        print(\"\\nOVERALL RANKINGS BY CONTEXT:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Best for each use case\n",
        "        for use_case, scores in use_case_scores.items():\n",
        "            ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            print(f\"\\nBest for {use_case.title()}:\")\n",
        "            for i, (system, score) in enumerate(ranked, 1):\n",
        "                print(f\"  {i}. {system}: {score:.1f}/100\")\n",
        "\n",
        "        # Overall balanced score\n",
        "        print(\"\\nBalanced Overall Score:\")\n",
        "        overall_scores = {}\n",
        "        for system in common_metrics.keys():\n",
        "            score = 0\n",
        "            # Common metrics (40% weight)\n",
        "            score += common_metrics[system][\"avg_confidence\"] * 10\n",
        "            score += common_metrics[system][\"track_consistency\"] * 15\n",
        "            score += common_metrics[system][\"coverage\"] * 15\n",
        "\n",
        "            # Average use case performance (60% weight)\n",
        "            use_case_avg = np.mean([scores[system] for scores in use_case_scores.values()])\n",
        "            score += use_case_avg * 0.6\n",
        "\n",
        "            overall_scores[system] = score\n",
        "\n",
        "        ranked_overall = sorted(overall_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        for i, (system, score) in enumerate(ranked_overall, 1):\n",
        "            print(f\"  {i}. {system}: {score:.1f}/100\")\n",
        "\n",
        "        # Save comprehensive results\n",
        "        self.results = {\n",
        "            \"common_metrics\": common_metrics,\n",
        "            \"specific_capabilities\": specific_metrics,\n",
        "            \"use_case_scores\": use_case_scores,\n",
        "            \"overall_ranking\": ranked_overall,\n",
        "            \"evaluation_type\": \"comprehensive_fair\"\n",
        "        }\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FAIR EVALUATION COMPLETE\")\n",
        "        print(\"Each system evaluated on its intended strengths\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    def calculate_track_consistency(self, detections):\n",
        "        \"\"\"Calculate how consistent tracks are\"\"\"\n",
        "        if not detections:\n",
        "            return 0\n",
        "\n",
        "        tracks = defaultdict(list)\n",
        "        for d in detections:\n",
        "            tracks[d.get(\"track_id\", 0)].append(d.get(\"frame_id\", 0))\n",
        "\n",
        "        consistencies = []\n",
        "        for track_id, frames in tracks.items():\n",
        "            if len(frames) > 1:\n",
        "                frames_sorted = sorted(frames)\n",
        "                gaps = [frames_sorted[i+1] - frames_sorted[i] for i in range(len(frames_sorted)-1)]\n",
        "                consistency = 1.0 / (1 + np.std(gaps)) if gaps else 1.0\n",
        "                consistencies.append(consistency)\n",
        "\n",
        "        return np.mean(consistencies) if consistencies else 0\n",
        "\n",
        "    def calculate_coverage(self, detections):\n",
        "        \"\"\"Calculate frame coverage\"\"\"\n",
        "        if not detections:\n",
        "            return 0\n",
        "\n",
        "        frames = set(d.get(\"frame_id\", 0) for d in detections)\n",
        "        if frames:\n",
        "            frame_range = max(frames) - min(frames) + 1\n",
        "            return len(frames) / frame_range if frame_range > 0 else 0\n",
        "        return 0\n",
        "\n",
        "# ================================\n",
        "# Run Comprehensive Fair Evaluation\n",
        "# ================================\n",
        "\n",
        "fair_evaluator = ComprehensiveFairEvaluator()\n",
        "fair_results = fair_evaluator.evaluate_all_systems(all_results)\n",
        "\n",
        "# Save fair evaluation results\n",
        "fair_eval_file = OUTPUT_DIR / \"fair_evaluation_report.json\"\n",
        "with open(fair_eval_file, \"w\") as f:\n",
        "    json.dump(fair_results, f, indent=2)\n",
        "\n",
        "print(f\"\\n✅ Fair evaluation report saved to: {fair_eval_file}\")"
      ],
      "metadata": {
        "id": "CEQ4BiwHwTq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff4ce89-21ca-44b4-8116-47ed341b4fbc"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "COMPREHENSIVE FAIR EVALUATION\n",
            "============================================================\n",
            "\n",
            "\n",
            "1. COMMON TRACKING METRICS\n",
            "----------------------------------------\n",
            "\n",
            "2. SYSTEM-SPECIFIC CAPABILITIES\n",
            "----------------------------------------\n",
            "\n",
            "3. USE CASE EVALUATION\n",
            "----------------------------------------\n",
            "\n",
            "Use Case Suitability Scores (0-100):\n",
            "\n",
            "  Real-time Tracking:\n",
            "\n",
            "  Tactical Analysis:\n",
            "\n",
            "  Research & Development:\n",
            "\n",
            "4. CONTEXTUALIZED RANKINGS\n",
            "----------------------------------------\n",
            "\n",
            "OVERALL RANKINGS BY CONTEXT:\n",
            "----------------------------------------\n",
            "\n",
            "Best for Realtime:\n",
            "\n",
            "Best for Tactical:\n",
            "\n",
            "Best for Research:\n",
            "\n",
            "Balanced Overall Score:\n",
            "\n",
            "============================================================\n",
            "FAIR EVALUATION COMPLETE\n",
            "Each system evaluated on its intended strengths\n",
            "============================================================\n",
            "\n",
            "✅ Fair evaluation report saved to: /content/output/fair_evaluation_report.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Download results\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print_status(\"Creating archive...\", \"INFO\")\n",
        "\n",
        "archive_name = \"tracking_results\"\n",
        "archive_path = BASE_DIR / archive_name\n",
        "\n",
        "shutil.make_archive(str(archive_path), 'zip', OUTPUT_DIR)\n",
        "\n",
        "print_status(\"Downloading...\", \"SUCCESS\")\n",
        "files.download(f\"{archive_path}.zip\")\n",
        "\n",
        "print_status(\"Complete!\", \"SUCCESS\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}